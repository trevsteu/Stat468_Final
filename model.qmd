---
title: "Model2"
author: "Trevor S"
---

## Setup

We install and load the necessary packages, along with functions from prior chapters.

```{r,  message = FALSE, warning = FALSE}
# renv::install("patchwork")
# renv::install("stringr")
# renv::install("reactable")

library(patchwork)
library(stringr)
library(reactable)

source("functions.R") # load functions defined in prior chapters
```

## Introduction/Recap

Now that we have metrics representing different ways of calculating the historical value of a draft pick, we can now develop models for predicting the value of future picks. First, we will fit a linear regression model to the data, an then we will develop a model via non-linear regression. We will then put the models on the same scale by multiplying each predicted value by a constant, allowing us to compare models more effectively. Note that the following two Stack Overflow posts were once again very helpful when writing the code in this chapter:

-   [Dynamic Variable naming in r](https://stackoverflow.com/questions/20855818/dynamic-variable-naming-in-r)

-   [Specifying column with its index rather than name](https://stackoverflow.com/questions/16187091/specifying-column-with-its-index-rather-than-name)

Recall the four plots we ended the Transform chapter with this plot, based on the mean PS, mean GP, success rate, and mean adjusted PS for every selection between 1 and 224. For convenience we replot this data below:

```{r}
(plot_mean_ps + plot_mean_gp) / (plot_mean_adj_ps + plot_suc_rate)
```

## Linear Regression

We use `lm` to fit a linear model to each of the metrics. Note we use a logistic regression model for fitting the model which estimates the probability of a player becoming an NHL regular.

```{r}
metrics <- c("ps", "gp", "adj_ps")
overall <- all_data_adj$overall

lin_models <- lapply(metrics, \(x) lm(all_data_adj[[x]] ~ overall))

logist_model <- glm(all_data_adj$reg ~ overall, family = "binomial")
```

For each linear model, we generate the fitted values. The fitted values are given in the table below:

```{r}
lm_pred_vals <- lapply(seq(1,3), 
                      \(x) predict(lin_models[[x]], 
                                   data.frame(overall = seq(1,224))))

logist_pred_vals <- predict(logist_model, data.frame(overall = seq(1,224)))


lm_pred_vals <- data.frame(overall = seq(1, 224), 
                          ps = lm_pred_vals[[1]], 
                          gp = lm_pred_vals[[2]], 
                          adj_ps = lm_pred_vals[[3]], 
                          p_reg = exp(logist_pred_vals) / 
                            (1 + exp(logist_pred_vals)))

reactable(round(lm_pred_vals, 4))
```

Next we plot the fitted values. The fitted lines are plotted on top of the average values, we use the average values to make the plot easier to read (but the lines were fit using the raw values).

```{r}
names <- c("PS", "GP", "Adjusted PS", "Probability of Success")

for(i in 1:length(metrics)){
  assign(str_glue("plot_{metrics[i]}"), 
         ggplot(all_data_comb, aes_string(x = "overall", y = str_glue("mean_{metrics[i]}"))) + 
           geom_point(alpha = 0.5) + 
           labs(title = str_glue("{names[i]} verses Overall"), 
                x = "Overall", y = str_glue("{names[i]}")))
}

for(i in 1:length(metrics)){
  assign(str_glue("plot_lm_{metrics[i]}"), 
         get(str_glue("plot_{metrics[i]}")) + 
           geom_line(data = lm_pred_vals, aes_string(x = "overall", y = metrics[i]), 
                     col = "red", lwd = 1.5))
}

plot_lm_p_reg = ggplot(all_data_comb, aes(x = overall, y = suc_rate)) + 
  geom_point(position = "jitter", alpha = 0.5) + 
  geom_line(data = lm_pred_vals, aes(x = overall, y = p_reg), col = "red", lwd = 1.5)

(plot_lm_ps + plot_lm_gp) / (plot_lm_adj_ps + plot_lm_p_reg)
```

Based on the plots above, all four of these linear models are inadequate. Moreover, all of the models except for the one based on NHL regular probability fail our second requirement for a feasible model, which is that all picks have a strictly positive value. With this in mind, we move onto fitting a non-linear model.

## Non-Linear Regression

Given that none of the four linear models were appropriate, we will reattempt to fit a model using non-linear regression (ie the `nls` function, which stands for non-linear least squares). The resource [Non-linear Regression in R](https://tuos-bio-data-skills.github.io/intro-stats-book/non-linear-regression-in-R.html) was very helpful when working on this section. In short, we will be fitting the model

$$ v_{i,m} = \frac{\phi_{1, m}}{1+e^{(\phi_{2,m}- i)/\phi_{3,m}}} $$

Where

-   $i$ is the pick number.

-   $m$ is the metric being used.

-   $v_{i,m}$ is the value of pick $i$ based on metric $m$.

-   $\phi_{1, m},\phi_{2, m},\phi_{3, m}$ are parameters we are estimating which depend on which metric we are using.

We choose to use `nls` because it allows us to directly fit a model with non-linear parameters, we do not need to transform the explanatory or response variates so it makes interpretations significantly easier. We fit these models as follows, except we do not use the :

```{r}
metrics <- c("ps", "gp", "adj_ps")

overall <- all_data_adj$overall

for(i in seq(1,3)){
  assign(str_glue("nls_{metrics[i]}"), 
         nls(all_data_adj[[i+4]] ~ SSlogis(log(overall), phi1, phi2, phi3)))
}

nls_pred_vals <- lapply(seq(1,3), 
                      \(i) predict(get(str_glue("nls_{metrics[i]}")), 
                                   data.frame(overall = seq(1,224))))

nls_pred_vals <- data.frame(overall = seq(1, 224), 
                          ps = nls_pred_vals[[1]], 
                          gp = nls_pred_vals[[2]], 
                          adj_ps = nls_pred_vals[[3]])
reactable(round(nls_pred_vals, 4))
```

We now plot the fitted line. We once again use plot the line on top of the historical averages to make the plot easier to read.

```{r, fig.asp=1}
for(i in seq(1,3)){
  assign(str_glue("plot_nls_{metrics[i]}"), 
         ggplot(all_data_comb, 
                aes_string(x = "overall", y = str_glue("mean_{metrics[i]}"))) + 
           geom_point() + 
           geom_line(data = nls_pred_vals, 
                     aes_string(x = "overall", y = str_glue("{metrics[i]}")), 
                     col = "red", lwd = 1.5))
}


plot_nls_ps / plot_nls_gp / plot_nls_adj_ps
```
