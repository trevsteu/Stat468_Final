---
title: "Model"
author: "Trevor S"
---

## Setup

We install and load the necessary packages, along with functions from prior chapters.

```{r,  message = FALSE, warning = FALSE}
# renv::install("patchwork")
# renv::install("stringr")
# renv::install("reactable")
# renv::install("nlstools")

library(patchwork)
library(stringr)
library(reactable)
library(nlstools)

source("functions.R") # load functions defined in prior chapters
```

## Introduction/Recap

Now that we have metrics representing different ways of calculating the historical value of a draft pick, we can now develop models for predicting the value of future picks. First, we will fit a linear regression model to the data, an then we will develop a model via non-linear regression. We will then put the models on the same scale by multiplying each predicted value by a constant, allowing us to compare models more effectively. As always, when fitting a model it is important to ensure that the underlying assumptions of a model hold, otherwise the model can be useless, or even worse, misleading. Note that the following two Stack Overflow posts were once again very helpful when writing the code in this chapter:

-   [Dynamic Variable naming in r](https://stackoverflow.com/questions/20855818/dynamic-variable-naming-in-r)

-   [Specifying column with its index rather than name](https://stackoverflow.com/questions/16187091/specifying-column-with-its-index-rather-than-name)

Recall the four plots we ended the Transform chapter with, based on the mean PS, mean GP, success rate, and mean adjusted PS for every selection between 1 and 224. For convenience we replot this data below:

```{r}
(plot_mean_ps + plot_mean_gp) / (plot_suc_rate + plot_mean_adj_ps)
```

## One Last Adjustment 

One notable issue with our non-linear model is that most of the models are on very different scales (Mean PS and Mean Adjusted PS goes up to about 100, Mean GP goes up to roughly 1200, and Success Rate only goes up to a maximum of 1). We would like to standardize this to allow for a more direct comparison of models. To do this, we will calculate $C_m = \frac{1000}{h_{1,m}}$, and then multiply the historical value of every pick by $C_m$ to get a value out of 1000 where $h_{1, m} = 1000$ for all metrics. Another point in favour of rescaling is to maintain consistence with existing work such as the research listed in the Question Chapter, which typically make the 1st overall pick worth 1000 "points" and then calculate the relative value of other picks based on that. We do this now because if we do it after fitting a model then we will have to refit all the models anyway.

```{r}
C_m <- c(1, 1000 / all_data_comb[1,][-1])

all_data_scaled <- all_data_comb * C_m

reactable(all_data_scaled) # confirm it worked
```

Now that all metrics are on the same scale, we can plot them on top of each other.

```{r}
ggplot(all_data_scaled, aes(x = overall)) + 
  geom_point(aes(y = mean_ps), col = "salmon", alpha = 0.7) +   
  geom_point(aes(y = mean_gp), col = "dodgerblue", alpha = 0.3) + 
  geom_point(aes(y = suc_rate), col = "purple", alpha = 0.3) + 
  geom_point(aes(y = mean_adj_ps), col = "limegreen", alpha = 0.3)
```

This plot confirms that mean PS and adjusted PS give very similar estimates, and that value decreases slowest when using Success Rate. Now that we have the plots on the same scale, we can fit models to the scaled data.

## Linear Regression

We use `lm` to fit a linear model to each of the metrics:

```{r}
metrics <- c("mean_ps", "mean_gp", "suc_rate", "mean_adj_ps")
overall <- all_data_scaled$overall

lin_models <- lapply(metrics, \(x) lm(all_data_scaled[[x]] ~ overall))
```

For each linear model, we generate a vector of predicted values and plot it on top of the historical values:

```{r}
lm_pred_vals <- lapply(seq(1,4), 
                      \(x) predict(lin_models[[x]], 
                                   data.frame(overall = seq(1,224))))

lm_pred_vals <- data.frame(overall = seq(1, 224), 
                          mean_ps = lm_pred_vals[[1]], 
                          mean_gp = lm_pred_vals[[2]], 
                          suc_rate = lm_pred_vals[[3]], 
                          mean_adj_ps = lm_pred_vals[[4]])

names <- c("Mean PS", "Mean GP", "Success Rate", "Mean Adjusted PS")

for(i in 1:length(metrics)){
  assign(str_glue("plot_{metrics[i]}"), 
         ggplot(all_data_scaled, aes_string(x = "overall", y = metrics[i])) + 
           geom_point() + 
           labs(title = str_glue("{names[i]} verses Overall"), 
                x = "Overall", y = str_glue("{names[i]}")))
}

for(i in 1:length(metrics)){
  assign(str_glue("plot_lm_{metrics[i]}"), 
         get(str_glue("plot_{metrics[i]}")) + 
           geom_line(data = lm_pred_vals, aes_string(x = "overall", y = metrics[i]), 
                     col = "red", lwd = 1.5))
  }

(plot_lm_mean_ps + plot_lm_mean_gp) / (plot_lm_suc_rate + plot_lm_mean_adj_ps)
```

The fitted values are given in the table below:

```{r}
reactable(lm_pred_vals)
```

All four of these linear models are very clearly inadequate, but for sake of completeness we will look at plots of the residuals vs fitted values.

```{r}
lm_resids <- lapply(lin_models, residuals)

lm_resids <- data.frame(mean_ps_resid = lm_resids[[1]], 
                     mean_gp_resid = lm_resids[[2]], 
                     suc_rate_resid = lm_resids[[3]], 
                     mean_adj_ps_resid = lm_resids[[4]])

lm_pred_vals_resid <- cbind(lm_pred_vals, lm_resids)

for(i in 1:length(metrics)){
  assign(str_glue("plot_res_{metrics[i]}"), 
         ggplot(lm_pred_vals_resid, aes_string(x = str_glue("{metrics[i]}"), 
                                            y = str_glue("{metrics[i]}_resid"))) + 
           geom_hline(yintercept = 0, col = "red", lwd = 1.5) + geom_point())
  }

(plot_res_mean_ps + plot_res_mean_gp) / (plot_res_suc_rate + plot_res_mean_adj_ps)
```

Clearly none of these models are appropriate, they very clearly fail the assumptions regarding a correct functional form, constant variance of residuals, and independent residual assumptions. It is also clear that the errors are not normally distributed. Moreover, these models all fail our second requirement for a feasible model in the Approach section of the Question chapter (which is that all picks have a strictly positive value).

## Non-Linear Regression

Given that none of the four linear models were appropriate, we will reattempt to fit a model using non-linear regression (ie the `nls` function, which stands for non-linear least squares). The resource [Non-linear Regression in R](https://tuos-bio-data-skills.github.io/intro-stats-book/non-linear-regression-in-R.html) was very helpful when working on this section. In short, we will be fitting the model

$$
v_{i,m} = \frac{\phi_{1, m}}{1+e^{(\phi_{2,m}- i)/\phi_{3,m}}}
$$

Where

-   $i$ is the pick number.

-   $m$ is the metric being used.

-   $v_{i,m}$ is the value of pick $i$ based on metric $m$.

-   $\phi_{1, m},\phi_{2, m},\phi_{3, m}$ are parameters we are estimating which depend on which metric we are using.

We choose to use `nls` because it allows us to directly fit a model with non-linear parameters, we do not need to transform the explanatory or response variates. We fit these models as follows:

```{r}
for(i in seq(1,4)){
  assign(str_glue("nls_{metrics[i]}"), 
         nls(all_data_scaled[[i+1]] ~ SSlogis(log(overall), phi1, phi2, phi3)))
}

nls_pred_vals <- data.frame(pick = seq(1, 224), 
                            mean_ps = predict(nls_mean_ps, pick), 
                            mean_gp = predict(nls_mean_gp, pick), 
                            suc_rate = predict(nls_suc_rate, pick), 
                            mean_adj_ps = predict(nls_mean_adj_ps, pick))

for(i in 1:length(metrics)){
  assign(str_glue("plot_nls_{metrics[i]}"), 
         get(str_glue("plot_{metrics[i]}")) + 
           geom_line(data = nls_pred_vals, aes_string(x = "overall", y = metrics[i]), 
                     col = "red", lwd = 1.5))
  }

(plot_nls_mean_ps + plot_nls_mean_gp) / (plot_nls_suc_rate + plot_nls_mean_adj_ps)
```

These curves all seem to fit well. We can also plot the curves on top of each other since they are on (roughly) the same scale. Note that the scales may not be exactly equal because the predicted value of the first pick may not be exactly 1000 points. When we pick a model we will rescale all the values so that this is the case but for the sake of comparing models this is good enough.

```{r}
ggplot(nls_pred_vals, aes(x = overall)) + 
  geom_line(aes(y = mean_ps), col = "salmon", lwd = 1.5, lty = 1) + 
  geom_line(aes(y = mean_gp), col = "dodgerblue", lwd = 0.85, lty = 2) +
  geom_line(aes(y = suc_rate), col = "purple", lwd = 0.85, lty = 3) +
  geom_line(aes(y = mean_adj_ps), col = "limegreen", lwd = 0.85, lty = 6)
```

The mean PS and mean Adjusted PS lines are almost perfectly on top of each other, indicating the adjustment we made to estimate the PS remaining in players' careers had a minimal impact on the estimate of pick value. Indeed:

```{r}
mean(abs(nls_pred_vals$mean_ps - nls_pred_vals$mean_adj_ps))
```

This tells us that the mean distance between pick value estimated by mean PS and mean Adjusted PS is about 1.5 points, which is effectively nothing since picks are valued out of 1000 points.

## Model Selection

We have the following four models. Recall the model we fit is $v_{i,m} = \frac{\phi_{1, m}}{1+e^{(\phi_{2,m}- i)/\phi_{3,m}}}$ where $i$ is the pick number, $m$ is the metric being used, $v_{i,m}$ is the estimated value of pick $i$ based on model $m$, and $\phi_{1,m}, \phi_{2,m}, \phi_{3,m}$ are the parameters we estimated. Here are the each of the models we fit. In order, they are for mean PS, mean GP, Success Rate, and mean Adjusted PS:

```{r}
for(metric in metrics){
  print(get(str_glue("nls_{metric}")))
}
```

We now have four models which are backed by historical data. Additionally, all four of them seem feasible based on the criteria we noted in the Approach section of the Question chapter since clearly the lines we have fit are decreasing and $>0$ for all $i$ (since $\phi_{1,m} >0$ for all four models). Now that we know the models are all feasible, we check the model assumptions regarding independence, normality, and constant variance of the residuals.

```{r}
nls_fitted_resid <- cbind(nls_pred_vals, all_data_scaled[,-1] - nls_pred_vals[,-1])
colnames(nls_fitted_resid) <- c("overall", "mean_ps", "mean_gp", "suc_rate", 
                                "mean_adj_ps", "resid_mean_ps", "resid_mean_gp", 
                                "resid_suc_rate", "resid_mean_adj_ps")
```

Probably will take the model with the lowest RSS.

## Finishing Touches

Rescale so first pick is worth exactly 1000 points Create value and pick functions.
