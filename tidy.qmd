---
title: "Tidy"
author: "Trevor S"
---

## Setup

We install and load the necessary packages, along with functions from prior chapters.

```{r, message = FALSE, warning = FALSE}
# renv::install("rvest")
# renv::install("tidyverse")
# renv::install("gt")
# renv::install("reactable")
# renv::install("DBI")
# renv::install("duckdb")
# renv::install("aws.s3")
# renv::install("paws")
# renv::install("arrow")

library(rvest)
library(tidyverse)
library(stringr)
library(gt)
library(reactable)
library(DBI)
library(duckdb)
library(aws.s3)
library(paws)
library(arrow)

source("functions.R") # load functions defined in prior chapters
```

## Introduction

In the tidy step, we put the data into tidy form and clean it, which will make the data easier to analyze in the later steps. Despite the table from the previous chapter *looking* fairly clean, further inspection reveals some issues:

```{r, warning = FALSE}
gt(import_draft(start_year)[23:30,])
```

Some problems that immediately come up are:

-   Two rows get inserted at the end of every round to indicate the round changed.

-   Though not visible because of the usage of `gt`, numbers are being coded as strings (`overall`, `age`, `to`, etc).

-   (At least) one player is missing everything except for their pick number, name, team, position, nationality, and amateur team.

-   The `+/-` column got renamed to `x`

-   There were two `gp` columns, one got automatically renamed to `gp2` when we used `janitor::clean_names()`

By doing a little bit of detective work with some of the other players with missing values elsewhere in the dataset, we notice that players who never played in the NHL have empty strings listed for everything except for the values attributes listed above. We will have to deal with this in the tidy step. Note that Hockey Reference begins listing player's ages in the 2001 draft, but we aren't going to use ages for our analysis so we won't bother coming up for a remedy for the players drafted between 1996 and 2000. The number of picks in the draft has also changed over the years, we will ignore any player drafted after selection 224 (the number of picks in the 2025 NHL Entry Draft). Finally, it would be helpful to remove the columns we don't care about.

## Cleaning

We build a function to tidy the data. In particular, we want it to:

-   Remove the rows added between rounds.

-   Correct the types of each column so we can use numeric columns in calculations.

-   Change `gp` and `ps` values to `0` for players who never played in the NHL or have a negative `ps`.

-   Standardize position to either be F (forward, any combination of LW, RW, C), D (defenceman), or G (goalie). Note that Kaspars Astashenko has his position listed as "D/W", a quick search of the [NHL website](https://www.nhl.com/player/kaspars-astashenko-8468000) reveals he was a defenceman.

-   If `is.na(to)`, then the player never played in the NHL, so set it to the draft year.

-   Add a `year` column so we can adjust the stats of players drafted more recently.

-   Select the columns we care about (`year`, `overall`, `pos`, `to`, `ps`, and `gp`) in that order.

-   Remove any players selected after 224$^{\text{th}}$ overall.

-   We don't care about `+/-`, so we can ignore the column being renamed since we won't be using it anyway.

-   It also turns out that for skaters `gp2` is empty and for goalies `gp` and `gp2` will have the same value, so this issue can be resolved by simply selecting `gp`.

-   The 69$^{\text{th}}$ pick of 2011 and 123$^{\text{rd}}$ pick of 2002 were forfeited and are listed as blank rows, so these should be removed.

Note that we cannot remove the round separating rows by removing a specified row number since many of the drafts in our dataset have different numbers of picks per round, and some rounds within the same draft have even had a different numbers of picks.

```{r, warning = FALSE, message = FALSE}
tidy_draft <- function(year){
  draft_year_table <- import_draft(year) |> 
    filter(overall != "Overall" & overall != "" & # remove extra rows
             as.numeric(overall) < 225 & # remove players drafted after pick 224
             amateur_team != "()") |> # remove invalid/forfeited picks 
    type_convert() |> # fix types 
    mutate("year" = year, "ps" = pmax(coalesce(ps, 0), 0), 
           "gp" = coalesce(gp, 0), "to" = coalesce(to, year), 
           "pos" = ifelse(str_count(pos, "G") == 1, "G", 
                          ifelse(str_count(pos, "D") == 1, "D", "F"))) |> 
    select(year, overall, to, pos, ps, gp) # columns we care about
  draft_year_table
}

reactable(tidy_draft(1996))
```

This is the form we will use for analysis later.

## Getting the Data

We now load in all of the data and use `rbind()` to bind the tables together, giving us a single data frame to work with. This also means that our data will be in a mix of long and wide format, since the `year` and `overall` columns are formatted like they are in long format but the `to`, `pos`, `gp`, and `ps` columns are the same as they would be in a wide format. Note that this function takes 2-3 minutes to run (because of the `Sys.sleep(5)` line, which is necessary to prevent us getting rate limited). We will find a workaround for this shortly so we don't have to run this function any more than we have to.

```{r, warning=FALSE, message=FALSE, eval = FALSE}
all_data <- do.call(rbind, lapply(seq(start_year, end_year, 1),
                   \(x) tidy_draft(x)))
```

```{r, message=FALSE, echo=FALSE, warning=FALSE}
con <- dbConnect(duckdb())

dbExecute(con, "INSTALL httpfs;")
dbExecute(con, "LOAD httpfs;")

all_data_test <- dbGetQuery(con, "SELECT * 
                            FROM read_parquet('s3://trevor-stat468/all_data.parquet');")

# I'm cheating here because I don't want to run the chunk above since 
#   tidy_draft takes such a llong time to run and render
```

## Verification

We can check that this data has loaded correctly, there should be between 5250 and 5600 rows (the number of picks in a draft has changed over the years in our dataset as we will see, but is always between 210 and 224 so 25 drafts will be between ) and 6 columns:

```{r}
dim(all_data) # confirm there are 5250-5600 rows and 6 columns

length(unique(all_data$year)) # confirm all 25 years have been included

gt(head(all_data, 10))

gt(all_data[23:30,])
```

These checks all returned what they should.

## Storing the Data

Finally, recall that the `import_data` function (and thus the `tidy_draft` function) both take quite a while to run, especially when importing data for a large number of years. To resolve this issue, we will store the data in an AWS S3 bucket so future chapters can get the data from the S3 bucket instead of from Hockey Reference, making this report render significantly faster. We do this by following the instructions given [here](https://medium.com/@som028/how-to-read-and-write-data-from-and-to-s3-bucket-using-r-3fed7e686844), which writes `all_data` to a parquet file and then saves it in our S3 bucket.

```{r}
Sys.setenv("AWS_ACCESS_KEY_ID" = Sys.getenv("AWS_ACCESS_KEY_ID"),
           "AWS_SECRET_ACCESS_KEY" = Sys.getenv("AWS_SECRET_ACCESS_KEY"), 
           "AWS_DEFAULT_REGION" = "us-east-2")
bucket = "trevor-stat468"

s3write_using(all_data, FUN = write_parquet, 
              bucket = bucket, object = "all_data.parquet")
```

In this and future chapters, we still start by loading in all of the functions from functions.R, which includes all the functions and global constants defined in all chapters, in addition to querying the data from the AWS S3 bucket using duckdb. The functions.R file is included in this project's GitHub repo, the part of it loads `all_data` is also given below (here we load it into `all_data_test` to show that it actually works). I also used this [blog post](https://francoismichonneau.net/2023/06/duckdb-r-remote-data/) to help me write the below code.

```{r}
con <- dbConnect(duckdb())

dbExecute(con, "INSTALL httpfs;")
dbExecute(con, "LOAD httpfs;")

all_data_test <- dbGetQuery(con, "SELECT * 
                            FROM read_parquet('s3://trevor-stat468/all_data.parquet');")

dim(all_data_test)
gt(head(all_data_test, 10))
```

In future chapters we will edit this data and will put the new version in the same S3 bucket. We proceed to the Visualize chapter.
