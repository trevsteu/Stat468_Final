---
title: "Transform"
author: "Trevor S"
---

## Setup

We install and load the necessary packages, along with functions and data from prior chapters.

```{r,  message = FALSE, warning = FALSE}
# renv::install("tidyverse")
# renv::install("dplyr")
# renv::install("gt")
# renv::install("reactable")
# renv::install("patchwork")
# renv::install("stringr")

library(tidyverse)
library(dplyr)
library(gt)
library(reactable)
library(patchwork)
library(stringr)

source("functions.R") # load functions defined in prior chapters
```

## Introduction

The first two metrics we will fit models to are GP and PS, in the Transform chapter, we will create the other two metrics which we will base our model off of.

The first transformation we will make in this chapter is to adjust our PS to better represent the careers of active players (ie those who have not retired yet). Recall that in the Visualize chapter we looked at the average PS of all players in out dataset drafted at pick $i$. As mentioned in the constraints section, one problem with this approach is that players drafted more recently will have had fewer years to generate PS. Figure 6.2.1 shows that, unsurprisingly, the total PS is quite a bit lower for the drafts between 2016 and 2020:

```{r}
all_data |> 
  group_by(year) |> 
  summarize(total_ps = sum(ps)) |>
  ggplot(aes(x = year, y = total_ps)) +
  geom_point() + 
  labs(title = "Total PS of Every Draft", 
       x = "Draft Year", y = "Total PS", 
       caption = "Figure 6.2.1: Total PS of Every Draft")
```

Considering this, it makes sense to make an adjustment to active players based on an estimate of the PS they will generate in the remainder of their career.

The other transformation we make in this chapter is to implement the method taken by @luo_improving_2024 which is to define a draft pick to be a "success" if that prospect becomes an NHL regular, which is defined to be playing in $\ge$ 200 NHL games for skaters. We will then fit a logistic regression model to estimate the probability of a player selected with pick $i$ becoming a regular NHL player. Note that @luo_improving_2024 using this definition for different analysis (he was evaluating prospect quality to better evaluate prospects, not value draft picks), but the applications are close enough and so we should be able to use his definition without any issues.

## Transforming PS

### Introduction

A similar issue to the one raised above is that there are quite a few players in our dataset who can still generate additional PS because they haven't retired. These two issues are related as it is probably reasonable to expect that the discrepancy between the 2016-2020 PS totals and the other years is at least partially due to there being so many active players who were drafted in that time frame. Indeed, we can see in Figure 6.3.1.1 that there are still a large number of active players from around the 2010 draft onward.

```{r}
active_players  <- all_data |> 
  filter(to == 2025) |> # recall to == 2025 if the player is still active
  group_by(year) |> 
  summarize(players = n()) |> 
  mutate(type = "Active")

retired_players <- all_data |> 
  filter(to < 2025 & to != year) |> # inactive players who played in the NHL
  group_by(year) |> 
  summarize(players = n()) |> 
  mutate(type = "Retired")

num_nhl_players <- rbind(retired_players, active_players)

ggplot(num_nhl_players, aes(x = year, y = players, col = type)) + 
  scale_color_manual(values = c("Active" = "forestgreen", "Retired" = "salmon")) + 
  geom_point(alpha = 0.8) + 
  labs(title = "Active and Retired Players in Each Draft", 
       x = "Draft Year", y = "Number of Players", 
       caption = "Figure 6.3.1.1: Number of Retired and Active Players", 
       col = "Player Status")
```

We can see that our dataset has quite a few active players, and the full value of these players' careers cannot be fully known. As an aside, it is interesting that PS is so high for the drafts between 2010 and 2015 even though there are still so many active players from those drafts. The 2015 draft is widely considered to be on of the best drafts ever, which explains why it does not follow the general decreasing trend after 2014, but this does not explain why the other drafts were so high. I guess it is possible the drafts between 2010 and 2014 were also really strong drafts, but it seems odd that there would be 6 strong drafts in a row. I did a little bit of research but couldn't find anything about it. It certainly appears that an adjustment is required to give more recent draft classes more weight when fitting our regression models.

Estimating the remaining value of a player's career could be an entire project all on its own so we obviously won't do anything too involved, but we have 3 options:

-   Only include drafts from before 2003 (there are no active NHL players who were drafted in 2002 or earlier).

-   Ignore this issue altogether (as if every active player in our dataset retired right now).

-   Make some sort of adjustment to the PS values of active players to account for the remainder of their career.

Neither of the first two options are particularly appealing. The first is unideal because of sample size concerns and the changes that have taken place in terms of draft eligibility and strategy since the 1980s (which we would need to include to maintain a sample size of 25). The second option is also not great because it will severely underestimate the quality of star players drafted in the last few years (elite players can play for 15-20 seasons, so we could be missing three quarters of a player's career if he was drafted in 2020). Thus we will attempt to estimate the remaining value of a player's career.

Estimating the remaining value of a player's career could be an entire project all on its own, but we will make an adjustment that should reduce the impact of this issue (while acknowledging that we will not completely fix it). Let $gp_{ij}$ and $ps_{ij}$ be the GP and PS of the player drafted at pick $i$ of draft $j$. If the player is retired then no adjustment is required, so we set $ps_{ij}^{adj} = ps_{j}$. If that player has not retired, we will set $ps^{adj}_{ij} = ps_{ij} + \frac{ps_{ij}}{gp_{ij}} \times \hat{gr_j}$, where $\hat {gr_j}$ is our [**estimate**]{.underline} of the number of games left in the career of players drafted in year $j$. We will set $\hat{gr_j} = \frac{gp_{ij}}{years_{ij}} \cdot \hat{yr_j}$, where $years_{ij}$ is the number of years since player $ij$ was drafted and $\hat{yr_j}$ is the estimated number of years left in their career. Thus the estimated number of games remaining in a player's career is their average number of games per season times the estimated number of years remaining. Simplifying, we have $ps_{ij}^{adj} = ps_{ij} + \frac{ps_{ij}}{years_{ij}} \cdot\hat{yr_{ij}}$. We will estimate $yr_j$ later using data from 1996-2004. When we code this adjustment later in this chapter we will verify that the PS values of drafts with a large number of active players end up looking similar to drafts where everyone is retired.

### Estimating Remaining Career Length

Let $yr_j$ be the number of years players drafted in draft $j$ have remaining in their career, given they were drafted $k$ years ago. We aim to estimate this value, and will do so by setting $\hat{yr_j}$ to be the mean career length of players who retired at $k$ years after being drafted and were drafted between 1996 and 2004. We calculate it for $1 \le k \le 22$ to make the indexing more intuitive, even though we will only be using the values $k \ge 5$, since no active player drafted in 2020 or earlier can have played for less than 4 seasons.

```{r}
get_length <- Vectorize(function(len){ 
  all_data |> 
    mutate(rem_career_len = to - year - len) |> 
    filter(year %in% 1996:2004 & rem_career_len >= 0) |> 
    summarize(mean = mean(rem_career_len)) |> 
    pull(mean)
})

est_yr <- data.frame(k = seq(1,22)) |>
  mutate(yr = get_length(k)) 

ggplot(est_yr, aes(x = k, y = yr)) + 
  geom_point() 

gt(est_yr)
```

The interpretation for this is that a current NHL player who was drafted 1 year ago has an estimated 9.48 years left in their career, a current NHL player who was drafted 5 years ago has an estimated 6.47 years left in their career, and on.

### Adjusting PS Values

Now that we have estimated the remaining number of years for each active NHL player, we can estimate the total PS for their career. Recall that in the introduction of this chapter we said $ps_{ij}^{adj} = ps_{ij} + \frac{ps_{ij}}{years_{ij}} \cdot\hat{yr_{ij}}$.

```{r}
active_players <- all_data |> 
  filter(to == 2025) |> 
  mutate(career_len = to - year) |> 
  mutate(adj_ps = ps + round(ps / career_len * get_length(career_len), 2)) |> 
  select(-career_len)

inactive_players <- all_data |> 
  filter(to != 2025) |> 
  mutate(adj_ps = ps)


all_data_adj <- rbind(active_players, inactive_players)
reactable(all_data_adj)
```

Note that the adjusted PS values for players who are expected to retire soon may not have changed much, if at all. To say it again, this estimation is not perfect, but it is better than the alternatives (using older data or ignoring the issue). In particular, this method assumes all players will continue to generate PS and play in games at the same rate as they have to this point in their career, and that the number of additional years a player will play for only depends on how many years ago they were drafted.

### Evaluating our Adjustment

We can do some checks to see if these estimates seem reasonable. First, we look at a plot of the PS values before and after the adjustment. We will plot all years for sake of comparison, but recall we only made changes for active players, and thus the drafts between 1996 and 2002 were completely unaffected (and thus the points are on top of each other):

```{r}
all_data_adj |> 
  group_by(year) |> 
  summarize(total_ps = sum(ps), total_adj_ps = sum(adj_ps)) |>
  pivot_longer(cols = starts_with("total"), 
               names_to = "metric", values_to = "value") |> 
  ggplot(aes(x = year, y = value, col = metric)) +
  geom_point()
```

It seems our adjustment was worthwhile since the drafts after 2010 (which are the drafts with a large number of active players) saw their PS values go up substantially.

Next, we check the magnitude of our changes by calculating the mean and standard deviation of $p_{ij}$ for $j \in \{ 1996, ..., 2004\}$, $p_{ij}$ for $j \in \{ 2012, ..., 2020 \}$, and $p_{ij}^{adj}$ for $j \in \{ 2012, ..., 2020\}$. Note that the intervals are the same size and that the first interval is years where almost all players have retired, and the second interval contains years with more heavily adjusted drafts.

```{r}
mean_sd <- function(data){
  c(mean(data), sd(data))
  }
  
mean_sd(filter(all_data_adj, year <= 2004)$ps)

mean_sd(filter(all_data_adj, year >= 2012)$ps)

mean_sd(filter(all_data_adj, year >= 2012)$adj_ps)
```

Our adjustment looks quite good since the mean and standard deviation of the first and third sets seem close, indicating the adjusted PS values for drafts we adjusted "look like" the true PS values. Additionally, the first and second sets look quite different, suggesting that the adjustment we made was necessary.

Another way we can check if the adjusted drafts seem similar to the drafts which required little adjustment is by comparing a histogram of the drafts between 1996 and 200 with the drafts between 2016 and 2020. Of course, we're not expecting them to be perfectly identical because there is a fair amount of variation even between drafts that required little to no adjustment (ex 1999 and 2003).

```{r, message=FALSE, warning=FALSE}
all_data_adj |> 
  pivot_longer(cols = c(ps,adj_ps), 
               names_to = "metric", values_to = "value") |> 
  filter((year %in% 1996:2000 & metric == "ps") | (year %in% 2016:2020 & metric == "adj_ps")) |> 
  ggplot(aes(x = value, fill = metric)) + 
  geom_histogram(position = "dodge")
```

These are a bit hard to compare because the tail gets so small so fast, but the values close to 0 look similar enough. We can zoom in on the tail, note that there isn't much to look at after 100:

```{r, message=FALSE, warning=FALSE}
all_data_adj |> 
  pivot_longer(cols = c(ps,adj_ps), 
               names_to = "metric", values_to = "value") |> 
  filter((year %in% 1996:2000 & metric == "ps") | (year %in% 2016:2020 & metric == "adj_ps")) |> 
  ggplot(aes(x = value, fill = metric)) + 
  geom_histogram(position = "dodge") + 
  coord_cartesian(xlim = c(8.5, 100))
```

There seem to be a similar number of observations in each bin, so it seems like our estimations are reasonable. Note again that we are clear restrictions and potential sources of error with this approach, and in the model step we will fit a model using both the raw PS values and the adjusted PS values. Before moving on to the model step, we create a plot of the mean PS and adjusted PS values, which is the same as the last plot from the Visualize chapter, except we will be including the adjusted PS values.

```{r, warning=FALSE}
all_data_adj |> 
  pivot_longer(cols = c(ps, adj_ps), names_to = "metric", values_to = "value") |> 
  group_by(metric, overall) |> 
  summarize(mean_val = mean(value)) |> 
  ggplot(aes(x = overall, y = mean_val, col = metric)) + 
  geom_point(alpha = 0.4)
```

The mean Adjusted PS values are all are greater than or equal to the mean unadjusted PS values, which is to be expected what we would expect because $ps^{adj}_{ij} \ge ps_{ij}$ as we add PS to players who are still active NHL players and do not change the PS values of retired players. This is the third of the four metrics we will use in the Model chapter, though we will use the raw Adjusted PS values rather than the aggregated values.

## Transforming GP

### Introduction

In this chapter we will add a column our dataset indicating whether the player became or is on track to become an NHL regular. We will adopt Luo's definition of an NHL regular being a skater who plays in or is on track to play in 200 games. This is straightforward a player is retired or has already played in enough games, but is more complex if the player is active and has not yet reached the required number of games. For these players, we will take an almost identical approach as Luo (2024), which changes the GP threshold depending on when a player was drafted. The modified threshold for skaters is given below, where $j$ is the year the player was drafted in $t_j$ is the threshold for players drafted in year $j$.

$$t_j = \begin{cases}200 \text{,                if $j \le 2017$}\\ \frac{82\times(2025-j)}{3} \text{,    if $j \in \{ 2018, 2019, 2020 \}$}\\ \end{cases}$$

Luo did not consider goalies at all in his paper, so one of the changes we will make from Luo's equation is that the threshold for goalies will be $\frac{t_j}{2}$ because goalies take longer to develop and even the best goalies only play in approximately 75% of their teams' games. Thus 100 games for a goalie is around 2.5 seasons' worth, which is roughly equivalent to 200 games for a skater.

The only other difference between our threshold is Luo's is that the years are different, since Luo's work is from a year ago and used data from slightly different years. Additionally, Luo did some checks to make sure this estimate is appropriate, it turned out to be quite a good predictor of whether a player will play in 200 games. Here is a plot of the skater threshold for games played based on the skater's draft year.

### Adding the Indicator

```{r, warning = FALSE}
get_threshold <- function(year){  
  ifelse(year <= 2017, 200, 82/3*(2025-year)) 
} 

thresholds <- data.frame(year = seq(2015,2020)) |>    
  mutate(t = get_threshold(year))  

ggplot(thresholds, aes(x = year, y = t)) +    
  geom_point() +   
  scale_x_discrete(limits = seq(2015, 2020))

gt(thresholds)
```

We make this transformation in R, first for retired players, then for active players, and then use `rbind` ro combine them.

```{r}
all_data_ret <- all_data_adj |>    
  filter(to != 2025) |>   
  mutate(thresh = ifelse(pos == "G", 100, 200),           
         reg = gp >= thresh) |>    
  select(-thresh)  

all_data_act <- all_data_adj |>    
    filter(to == 2025) |>    
  mutate(thresh = ifelse(pos == "G", get_threshold(year) / 2,                           
                         get_threshold(year)),         
         reg = gp >= thresh) |>    
  select(-thresh)  

all_data_adj <- rbind(all_data_ret, all_data_act)
```

We have now added the column necessary to create a model based on whether an NHL player became an NHL regular. We won't use the aggregated values to fit a model, but to see if this metric has potential we aggregate the data to get the success rate of every pick number and then plot it to ensure the success rate generally decreases ad the draft goes on.

```{r}
all_data_adj |>    
  group_by(overall) |>    
  summarize(rate = mean(reg)) |>    
  ggplot(aes(x = overall, y = rate)) +
  geom_point()
```

This plot has a similar shape to the plots at the end of the Visualize chapter. We will use the raw `TRUE`/`FALSE` values to fit a model in the Model chapter.

## Combining Everything

Now that we have the metrics we will use in the Model chapter, we will combine them into a single data frame to make the modelling as straightforward as possible. We also make a plot of the average values by pick each metric, note that no points can be directly on top of each other because all points have different `overall` values. When we fit the models we will use the raw values, but as seen in the Visualize chapter it is basically impossible to infer anything from the raw value plots. Note that the following two Stack Overflow posts were particularly helpful when writing this code:

-   [Dynamic Variable naming in r](https://stackoverflow.com/questions/20855818/dynamic-variable-naming-in-r)

-   [Specifying column with its index rather than name](https://stackoverflow.com/questions/16187091/specifying-column-with-its-index-rather-than-name)

```{r}
all_data_comb <- all_data_adj |> 
  group_by(overall) |> 
  summarize(mean_ps = mean(ps), 
            mean_gp = mean(gp), 
            mean_adj_ps = mean(adj_ps),
            suc_rate = mean(reg))

metrics <- c("mean_ps", "mean_gp", "mean_adj_ps", "suc_rate")
names <- c("Mean PS", "Mean GP", "Mean Adjusted PS", "Success Rate")

for(i in 1:length(metrics)){
  assign(str_glue("plot_{metrics[i]}"), 
         ggplot(all_data_comb, aes_string(x = "overall", y = metrics[i])) + 
           geom_point() + 
           labs(title = str_glue("{names[i]} verses Overall"), 
                x = "Overall", y = str_glue("{names[i]}")))
}

(plot_mean_ps + plot_mean_gp) / (plot_mean_adj_ps + plot_suc_rate)
```

These plots all have the same general shape, though some of them are on different scale. In the next chapter we will fit a model to the raw data, put the models on the same scale, and evaluate the models.

## Storing the Transformations

As touched on at the very end of the Tidy chapter, we will be storing our data frames in our S3 bucket. We use the same code to add `all_data_adj` and `all_data_comb` to our S3 bucket within AWS. In functions.R we get these data frames by querying the S3 bucket using duckdb.

```{r}
Sys.setenv("AWS_ACCESS_KEY_ID" = Sys.getenv("AWS_ACCESS_KEY_ID"),
           "AWS_SECRET_ACCESS_KEY" = Sys.getenv("AWS_SECRET_ACCESS_KEY"), 
           "AWS_DEFAULT_REGION" = "us-east-2")
bucket = "trevor-stat468"

s3write_using(all_data_adj, FUN = write_parquet, 
              bucket = bucket, object = "all_data_adj.parquet")
s3write_using(all_data_comb, FUN = write_parquet, 
              bucket = bucket, object = "all_data_comb.parquet")
```
