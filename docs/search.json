[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat468 Final Project",
    "section": "",
    "text": "1 Introduction",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "Stat468 Final Project",
    "section": "1.1 Abstract",
    "text": "1.1 Abstract\nIn the days of and leading up to the 2025 NHL Entry Draft there were a total of 18 trades which only included draft picks. This report aims to use historical data to determine the relative value of selections in the NHL Entry Draft. To do this, data will be imported from Hockey Reference, and several potential models will be fit to the data with the goal of predicting the value of each pick based on historical outcomes. The Shiny app component of this project allows users to interactively check the fairness of potential trades. Knowing the relative value of picks allows NHL teams to both make favourable trade offers as well as evaluate incoming trade offers. Specifically, this project makes contributions to both asset valuation as well as trade analysis, both in the context of selections in the NHL Entry Draft.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "Stat468 Final Project",
    "section": "1.2 Data",
    "text": "1.2 Data\nThe data used by this report is imported from Hockey Reference, which has data on NHL drafts dating back to 1963. Each row on Hockey Reference is one player selected, the columns included on the site are:\n\nOverall: the selection number where the player was selected.\nTeam: the team that selected the player.\nPlayer, Nat, Pos, Age: the player’s name, nationality, position, at age at the time of the draft.\nTo: the last year a player played in the NHL. For players who never played in the NHL this will be the empty string, for active players it will be 2025.\nAmateur Team: the team the player was drafted from (confusingly this is not necessarily an amateur team, a large number of players have been drafted from professional European teams).\nGP, G, A, PTS, +/-, PIM: the player’s career games played, goals, assists, points (goals plus assists), plus minus, and penalty minutes. For players who never played in the NHL these will all be empty strings. For goalies, this GP column will match the next GP column for goalies, and these values can be, but are are not necessarily, the empty string for goalies (eg a goalie could have gotten an assist). Note that I will abbreviate games played to GP throughout this report.\nGP, W, L, T/O, SV%, GAA: for goalies only, the goalie’s career games played, wins, losses, ties plus overtime losses, save percentage, and goals against average. For goalies who never played in the NHL and all skaters, these columns will all be empty strings.\nPS: the player’s estimated point shares, or points added to their team over the course of their career (here we mean points in the standings, NOT goals and assists). There is more info on point shares here. Note that I abbreviate point share to PS throughout this report.\n\nAll stats listed only pertain to regular season games, which is preferable anyway since we do not want to put players who played on bad teams at a disadvantage more than they already are (it’s harder to get a high PS if your team rarely wins). Note that we will only use a subset of the years between 1963 and 2025 and of the attributes listed above, as will be explained in the Import and Tidy chapters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "index.html#constraints",
    "href": "index.html#constraints",
    "title": "Stat468 Final Project",
    "section": "1.3 Constraints",
    "text": "1.3 Constraints\nThere are a number of technical and practical constraints at play. Here are some of them:\n\nThere have been 63 drafts in NHL history, but drafts which occurred too long ago are likely not relevant and drafts which occurred very recently are difficult to evaluate. Despite this, we would like to include as many drafts as possible to maintain a reasonable sample size. This will be discussed further in the Import chapter.\nMeasuring the value of a player’s career is not a trivial task. One of the metrics we will use is called point share, which is calculated by Hockey Reference and incorporates several stats, but it is still not a perfect metric as it can still be dependent on external factors, such as the quality of the player’s team the opportunities the player was given. We will discuss point share more in the Visualize, Transform, and Model chapters.\nFurthermore, measuring the value of an active (non retired) player’s career is even more difficult because they could still contribute to their team and thus their career could still increase in value. This leaves us with the following three options, which will be discussed further in the Transform chapter:\n\nIgnore the issue and act as if all active players retired today.\nAvoid the problem by only using data from draft classes in which all players have retired.\nTry to estimate the what the value of a player’s career will be when they retire and use that instead.\n\nWe are interested in using historical data to predict the value of a draft pick from the team’s perspective. One slight problem with this is that the value of the pick from the team’s perspective depends on how long the player stayed on their team and what (if anything) the team got when the player left the team (via trade, free agency, or retirement). We will ignore this because it is nearly impossible to take these factors into account.\nPlayers drafted earlier in a draft (ie with a better pick) typically get more opportunities than players selected in the later rounds. In particular, teams often fall victim to the sunk cost fallacy because scouts and management look bad when players who they invested a high pick into never makes it to the NHL. Accounting for this is either very difficult or impossible, so we will not attempt to remedy it.\nEvery draft has strong portions and weak portions. For example, draft A might have a very strong second round (by this we mean the prospects drafted in the second round of draft A are of higher quality than those typically drafted in the second round). Though this seems like an obvious point, it is crucial to mention because it is a significant asterisk on this report, which will assume all drafts have equal value structures (ie the quality of a prospect #27 overall of draft A is the same as the quality of a prospect drafted at # 27 of draft B).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "index.html#frequently-used-definitions",
    "href": "index.html#frequently-used-definitions",
    "title": "Stat468 Final Project",
    "section": "1.4 Frequently Used Definitions",
    "text": "1.4 Frequently Used Definitions\nWe define the following terms which will be used frequently throughout the report:\n\n\\(v_i\\): the true value of pick \\(i\\). This is unknown and is what we are trying to estimate.\n\\(\\hat v_i\\): our estimate of the value of pick \\(i\\).\n\\(h_{i, j, m}\\): the value of the \\(i^{th}\\) pick of draft \\(j\\) when we measure value using metric \\(m\\). We will consider this value known even though it needs to be estimated for certain metrics. Most of our metrics cannot be negative, so we have a lower bound on \\(h_{i, j, m}\\) for active players. Note that there are four metrics (possible values for \\(m\\)) that we will consider:\n\nPS: Point share. We sometimes use \\(ps_{i,j}\\) for the point share of the player drafted at pick \\(i\\) of draft \\(j\\).\nAdjusted PS: The player’s point share at the end of their career. We sometimes use \\(ps^{adj}_{i,j}\\) for the adjusted point share of the player drafted at pick \\(i\\) of draft \\(j\\). Note that for retired players we have \\(ps_{i,j}^{adj} = ps_{i,j}\\), since if a player is retired we know what their point share was at the end of their career. For active players we will consider this value known, even though it needs to be estimated.\nGP: Games played. We sometimes use \\(gp_{i,j}\\) for the number of games played by the player drafted at pick \\(i\\) of draft \\(j\\).\nNHL Regular: A player who played in (or is on track to play in) at least 200 NHL games. This definition is the same as the one used by Luo (2024), we will discuss it more in the Transform chapter.\n\n\n\n\n\n\nLuo, Hubert. 2024. “Improving NHL Draft Outcome Predictions Using Scouting Reports.” Journal of Quantitative Analysis in Sports 20 (4): 331–49. https://doi.org/10.1515/jqas-2024-0047.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Index</span>"
    ]
  },
  {
    "objectID": "question.html",
    "href": "question.html",
    "title": "2  Question",
    "section": "",
    "text": "2.1 Approach\nDepending on the context, there can be countless approaches one could take to define the relative value of each selection of an NHL Entry Draft. As one example, one could look at prior trades and then define the value of a pick to be what it has historically been traded for (the “market rate”), as was done by Isacke (2022) and Tulsky (2013). For example, this approach might say that pick \\(i\\) is typically traded for pick \\(j\\) and pick \\(k\\). This means that. This is not the approach we will take.\nIn contrast, this report will take the approach of defining the value of selection \\(i\\) to be the typical career contribution of players drafted at \\(i^{\\text{th}}\\) overall (we will define what “contribution” means when we pick a model). This matches the definition chosen by Moreau, Perera, and Swartz (2025) (NHL), Cacchione (2018) (MLB), and Liner (2020) (NBA) and is preferred in this context because we wish to find opportunities for general managers to make trades that help their team make trades which allow them to draft higher quality players. Using this definition of value will help NHL General Managers make data-backed decisions as opposed to using past trades as a starting point in trade negotiations. This is preferable since previous trades could be based on what “feels” favourable instead of what is favourable. Furthermore, in context of trades which only include draft picks, one team usually gets the better end of the trade. In other words, basing trades off what “feels” favourable doesn’t make a whole lot of sense because draft pick exchanges are typically only favourable to one team, not both.\nThis report will estimate \\(v_i\\) by fitting several regression models incorporating player contribution data by the players previously selected at pick \\(i\\). We will consider GP and PS as our metrics for measuring player quality (and thus the quality of a pick), and for most of them we will fit a linear and non-linear regression model.\nThe first two methods of evaluating player quality are similar to approaches taken by Moreau, Perera, and Swartz (2025), Cacchione (2018), and Liner (2020), and will take the PS (or GP) of all players taken at pick \\(i\\). Next, will consider a similar metric which adjusts the PS values for active players based on what we estimate their PS will be at the time of their retirement. The final approach is from Luo (2024), and will define an indicator random variable \\(Z_{ij} = 1\\) if and only if the player selected at pick \\(i\\) of draft \\(j\\) became, or is on track to become, an NHL regular. We will then fit a logistic regression model, giving us an estimate of the probability that a player selected at pick \\(i\\) will become an NHL regular. Thus in total we have four measures of the quality which will be considered: PS, GP, adjusted PS, and probability of becoming an NHL regular.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Question</span>"
    ]
  },
  {
    "objectID": "question.html#considerations",
    "href": "question.html#considerations",
    "title": "2  Question",
    "section": "2.2 Considerations",
    "text": "2.2 Considerations\nWe will fit 7 models in the Model chapter, so we need some criteria for what a feasible model looks like. We define a feasible model to be a model which satisfies both of the following:\n\n\\(v_i &gt; v_{i+k}\\) for all \\(i, k \\in \\mathbb Z^+\\)\n\nThis ensures later draft picks are not considered more valuable than picks earlier in the draft. This should intuitively make sense because the players available at pick \\(i+k\\) are a proper subset of the players available at pick \\(i\\), so there is no reason for a later pick to be more valuable in a trade context than an earlier pick.\n\n\\(v_i &gt; 0\\) for all \\(i \\in \\mathbb Z^+\\)\n\nEvery pick has a positive value since there is no real negative impact to picking a bad player, other than the opportunity cost of the “wasted” draft pick. Even if a player plays in NHL games and objectively contributes negatively to their team, this report takes the stance that the player has zero value instead of a negative value.\n\n\nWhile we will not include it in the definition of a feasible model, it is common knowledge in ice hockey circles (and confirmed by the previous work listed below) that NHL draft picks do not decrease in value linearly. In particular, \\(v_i\\) decreases quickly in \\(i\\), so the difference in value pick 1 and 30 is much greater than between pick 101 and 130 (ie \\(v_1 - v_{30} &gt;&gt;&gt; v_{101} - v_{130}\\)). In the Model chapter we will fit this model and show that it is not appropriate, before quickly moving on to non-linear models.\nNote that if picks did decrease linearly in value linearly then it would be very easy to create a model of draft pick value since we would have\n\\[ v_1 = v_2 + c = v_3 + 2c = ... = v_{224} + 223c \\]\nwhere \\(c &gt; 0\\), meaning we would only have to find the value of \\(c\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Question</span>"
    ]
  },
  {
    "objectID": "question.html#previous-work",
    "href": "question.html#previous-work",
    "title": "2  Question",
    "section": "2.3 Previous Work",
    "text": "2.3 Previous Work\nSome work in this area has been done before, such as:\n\nValuation of NHL Draft Picks using Functional Data Analysis (Moreau, Perera, and Swartz (2025))\nMLB Rule IV Draft: Valuing Draft Pick Slots (Cacchione (2018))\nDetermining the Value of NBA Draft Picks using Advanced Statistics (Liner (2020))\nExamining the value of NHL Draft picks (Isacke (2022))\nNHL draft: What does it cost to trade up? (Tulsky (2013))\n\nThis report will most closely follow the work done in the first three papers listed. As an interesting aside, Eric Tulsky, who wrote the last article listed above in 2013, was hired as General Manager of the Carolina Hurricanes in 2024.\n\n\n\n\nCacchione, Anthony. 2018. “MLB Rule IV Draft: Valuing Draft Pick Slots.” Dissertations and Theses, January. https://academicworks.cuny.edu/cc_etds_theses/754.\n\n\nIsacke, Curtis. 2022. “Examining the Value of NHL Draft Picks - Sound Of Hockey.” https://soundofhockey.com/2022/06/06/examining-the-value-of-nhl-draft-picks/.\n\n\nLiner, Jacob. 2020. “Determining the Value of NBA Draft Picks Using Advanced Statistics,” May. https://repository.arizona.edu/handle/10150/651330.\n\n\nLuo, Hubert. 2024. “Improving NHL Draft Outcome Predictions Using Scouting Reports.” Journal of Quantitative Analysis in Sports 20 (4): 331–49. https://doi.org/10.1515/jqas-2024-0047.\n\n\nMoreau, Ryker, Harsha Perera, and Tim Swartz. 2025. “Valuation of NHL Draft Picks Using Functional Data Analysis - Ryker Moreau, Harsha Perera, Tim B Swartz, 2025.” https://journals.sagepub.com/doi/10.1177/22150218251324875.\n\n\nTulsky, Eric. 2013. “NHL Draft: What Does It Cost to Trade up?  Broad Street Hockey.” https://www.broadstreethockey.com/post/nhl-draft-pick-value-trading-up/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Question</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "3  Import",
    "section": "",
    "text": "3.1 Setup\nWe install and load the necessary packages.\nCode\n# renv::install(\"rvest\")\n# renv::install(\"stringr\")\n# renv::install(\"tidyverse\")\n# renv::install(\"janitor\")\n# renv::install(\"gt\")\n# renv::install(\"reactable\")\n\nlibrary(rvest)\nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(gt)\nlibrary(reactable)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "import.html#introduction",
    "href": "import.html#introduction",
    "title": "3  Import",
    "section": "3.2 Introduction",
    "text": "3.2 Introduction\nIn the Import chapter we will import the data required for this report from Hockey Reference. Before we import any data, it’s important to consider which and how many years we want to include in this analysis.\nSince the NHL has changed dramatically over the years, we must be careful to ensure we do not include drafts from too long ago. There are two primary concerns with including data from too many years ago. First, requirements for a player to be eligible to be drafted in the first place have changed since the first NHL Draft in 1963; second, teams have likely changed their drafting approach and strategy over time.\nOne example of the first concern is that in 1979 the NHL began allowing players who had already played professionally for non-NHL teams to enter the draft. This meant that players who played professionally in Europe or in the World Hockey Association, which folded in 1979 would now be drafted. Thus the level of talent available to be drafted would generally be higher in drafts from 1979 onward (there were more players eligible to be picked). Thus if we included drafts prior to 1979 we would probably underestimate the value of later selections, because selections later in a draft would likely have more talent available. There have also been changes in regards to the ages of players who are eligible, currently players need to be between 18-20 as of September 15th of the Draft’s year.\nIn regards to the second concern, teams have likely become better at evaluating prospects as more advanced statistics have been developed, meaning that there are likely fewer late round draft “steals” in the 2020s than there were in the 1980s. Thus including drafts from the 1980s would skew our calculations, and we would likely overestimate the value of later picks, since the late round steals may have been drafted sooner if the teams of the 1980s had the resources available to teams today. Thus using drafts from the 1980s would make our model a poor predictor of draft pick value for drafts occurring in the 2020s.\nA clear example of the evolving draft strategies which could impact our conclusion is the fact that it is becoming increasingly rare for teams to draft older prospects, especially with high picks. For example, 9 of the first 10 picks in the 1980 NHL Entry Draft were 19 or 20 years old at the time of the draft. In contrast, the first 19 or 20 year old was not selected until the 49th pick of the 2025 NHL Entry Draft. Though the impact of this change is not clear, it demonstrates a clear shift in drafting strategy. Furthermore, it would not be surprising if the evaluation of prospects has changed over time too, which would change the relative value of picks (teams being more efficient drafters means later picks would be less valuable). With both of these concerns in mind, we clearly need to be careful about including drafts from too long ago.\nThat being said, players drafted in recent years have not had sufficient time to contribute to their teams, so we should not include drafts from too recently either. Ideally, we would wait until all players from a draft class have retired before including it in our analysis. Practically speaking, this is not feasible since players can have very long careers (for example, Alex Ovechkin was drafted in 2004 and is still playing) which would force us to include older drafts to maintain the same sample size, which is also not ideal as explained above.\nAnother consideration is that the formula for calculating a skater’s PS (point share; the metric we will use for predicting pick value) changed in either the 1997-1998 or 1998-1999 season. There is conflicting info on what year it changed; this link says it changed in 1998-1999 because time on ice data was not available until 1998-1999, however the page of 1997-1998 data has time on ice data. In the seasons where time on ice data was not available, games played was used instead. To maintain consistency, we would prefer to minimize the number of players in our dataset who played before the 1998-1999 season, since those seasons were definitely under the old PS formula. The PS formula for goalies has been the same since the 1983-1984 season, so it is not an issue.\nTaking these factors into consideration, we make the somewhat arbitrary decision to use the 25 drafts between and 1996 and 2020 (inclusive). We don’t have the code or the data to check this yet, but at the end of this chapter we will find the number of games played by players in our dataset under the old PS formula. It turns out that less than 0.2% of games in our dataset were played under the old PS formula and thus the disparity in formulas are unlikely to meaningfully impact our conclusion. However, this percentage would get progressively worse if we were to include more from prior to the 1997-1998 season. The dates included are similar to those included by Moreau, Perera, and Swartz (2025), which was origanlly published in 2020 and included players drafted between 1982 and 2016, inclusive.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "import.html#importing-the-data",
    "href": "import.html#importing-the-data",
    "title": "3  Import",
    "section": "3.3 Importing the Data",
    "text": "3.3 Importing the Data\nWe start off by creating a function while will import the data from a single draft. For sake of space we just look at the first 10 picks, the output is given in Figure 3.3.1\n\n\nCode\nstart_year &lt;- 1996\nend_year &lt;- 2020\n\nimport_draft &lt;- function(year){\n  url &lt;- str_glue(\"https://www.hockey-reference.com/draft/NHL_{year}_entry.html\")\n  html &lt;- read_html(url)\n  Sys.sleep(5) # to avoid getting rate limited\n  # the data is fairly easy to scrape, it's just an html table\n  draft_year_table &lt;- html |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt; \n    janitor::row_to_names(1) |&gt; \n    janitor::clean_names()\n  draft_year_table\n}\n\nimport_draft(start_year) |&gt; \n  head(10) |&gt; \n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 3.3.1: First 10 Picks of the 1996 Draft\") |&gt; \n  cols_label(amateur_team = \"Amateur Team\", gp_2 = \"GP\", x = \"+/-\",\n             t_o = \"T/O\", sv_percent = \"SV%\")\n\n\n\n\n\n\n\n\noverall\nteam\nplayer\nnat\npos\nage\nto\nAmateur Team\ngp\ng\na\npts\n+/-\npim\nGP\nw\nl\nT/O\nSV%\ngaa\nps\n\n\n\n\n1\nOttawa Senators\nChris Phillips\nCA\nD\n18\n2015\nPrince Albert Raiders (WHL)\n1179\n71\n217\n288\n68\n756\n\n\n\n\n\n\n64.6\n\n\n2\nSan Jose Sharks\nAndrei Zyuzin\nRU\nD\n18\n2008\nSalavat Yulaev Ufa (Russia)\n496\n38\n82\n120\n-40\n446\n\n\n\n\n\n\n25.8\n\n\n3\nNew York Islanders\nJ.P. Dumont\nCA\nRW\n18\n2011\nVal-d'Or Foreurs (QMJHL)\n822\n214\n309\n523\n-2\n364\n\n\n\n\n\n\n56.6\n\n\n4\nWashington Capitals\nAlexandre Volchkov\nRU\nC\n18\n2000\nBarrie Colts (OHL)\n3\n0\n0\n0\n-2\n0\n\n\n\n\n\n\n-0.1\n\n\n5\nDallas Stars\nRic Jackman\nCA\nD\n18\n2007\nSoo Greyhounds (OHL)\n231\n19\n58\n77\n-54\n166\n\n\n\n\n\n\n8.8\n\n\n6\nEdmonton Oilers\nBoyd Devereaux\nCA\nC\n18\n2009\nKitchener Rangers (OHL)\n627\n67\n112\n179\n5\n205\n\n\n\n\n\n\n12.5\n\n\n7\nBuffalo Sabres\nErik Rasmussen\nUS\nLW/C\n19\n2007\nMinnesota (WCHA)\n545\n52\n76\n128\n5\n305\n\n\n\n\n\n\n9.2\n\n\n8\nBoston Bruins\nJohnathan Aitken\nCA\nD\n18\n2004\nMedicine Hat Tigers (WHL)\n44\n0\n1\n1\n-12\n70\n\n\n\n\n\n\n0.0\n\n\n9\nAnaheim Ducks\nRuslan Salei\nBY\nD\n21\n2011\nLas Vegas Thunder (IHL)\n917\n45\n159\n204\n-25\n1065\n\n\n\n\n\n\n46.9\n\n\n10\nNew Jersey Devils\nLance Ward\nCA\nD\n18\n2004\nRed Deer Rebels (WHL)\n209\n4\n12\n16\n-30\n391\n\n\n\n\n\n\n2.7\n\n\n\nTable 3.3.1: First 10 Picks of the 1996 Draft\n\n\n\n\n\n\n\n\nWe compare the Figure 3.3.1 with the first 10 rows of the table on Hockey Reference, and it seems that the function we created does what we want it to do.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "import.html#evaluating-our-choice-of-drafts",
    "href": "import.html#evaluating-our-choice-of-drafts",
    "title": "3  Import",
    "section": "3.4 Evaluating our Choice of Drafts",
    "text": "3.4 Evaluating our Choice of Drafts\nWe can now find the number of skaters who played under the old PS formula. As mentioned earlier, it is not clear whether the PS formula changed in the 1997-1998 or 1998-1999 season, so we will check both. Note that players drafted in 1998 or later cannot have played in NHL games in the 1996-1997 or 1997-1998 seasons, so we only need to check players drafted in 1996 and 1997. Also, Hockey Reference URLs use the year the season ended in, so to get stats for the 1996-1997 season the year will be 1997. We also should take care when doing analysis with uncleaned data, in this case it turns out to not be an issue.\n\n\nCode\ndraft_1996_1997 &lt;- rbind(import_draft(1996), import_draft(1997)) |&gt; \n  filter(pos != \"G\") |&gt; # the ps formula for goalies is the same for our entire dataset\n  select(\"player\") # we just want to compare names\n\n# function to get the statistics for a given year so we can look at GP \n#    in just 1997 and 1998 (draft page only has career totals)\nplayer_stats &lt;- function(year){ \n  url &lt;- str_glue(\"https://www.hockey-reference.com/leagues/NHL_{year}_skaters.html\")\n  html &lt;- read_html(url)\n  Sys.sleep(5) # to avoid getting rate limited\n  stats_table &lt;- html |&gt; \n    html_element(\"table\") |&gt; \n    html_table() |&gt; \n    janitor::row_to_names(1) |&gt; \n    janitor::clean_names() |&gt; \n    type.convert() |&gt; \n    select(player, gp) |&gt; \n    group_by(player) |&gt; \n    # players who played for n &gt; 1 teams get listed n+1 times; this fixes it \n    summarize(gp = max(gp), .groups = \"drop\")  \n  stats_table \n}\n\nplayer_stats_1997_1998 &lt;- full_join(player_stats(1997), # year is end of season\n                                    player_stats(1998), # year is end of season\n                                    by = join_by(player))\n\n# get the players who played in 1996-1997 and/or 1997-1998\nold_ps_players &lt;- player_stats_1997_1998 |&gt; \n  rename(gp_1997 = gp.x, gp_1998 = gp.y) |&gt; \n  filter(player %in% draft_1996_1997$player) |&gt;\n  mutate(gp_1997 = coalesce(gp_1997, 0), # set NAs to 0\n         gp_1998 = coalesce(gp_1998, 0)) # set NAs to 0\n\nold_ps_players |&gt; \n  arrange(player) |&gt; \n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 3.4.1: Players with games in 1996-1997 and/or 1997-1998\") |&gt;\n  cols_label(gp_1997 = \"GP in 1996-1997\", gp_1998 = \"GP in 1997-1998\")\n\n\n\n\n\n\n\n\nplayer\nGP in 1996-1997\nGP in 1997-1998\n\n\n\n\nAndreas Dackell\n79\n82\n\n\nAndrei Zyuzin\n0\n56\n\n\nBoyd Devereaux\n0\n38\n\n\nBrad Larsen\n0\n1\n\n\nBrett Clark\n0\n41\n\n\nChris Allen\n0\n1\n\n\nChris Phillips\n0\n72\n\n\nDainius Zubrus\n68\n69\n\n\nDaniel Goneau\n41\n11\n\n\nDerek Morris\n0\n82\n\n\nErik Andersson\n0\n12\n\n\nErik Rasmussen\n0\n21\n\n\nJan Bulis\n0\n48\n\n\nJeff Brown\n1\n60\n\n\nJoe Thornton\n0\n55\n\n\nJohan Lindbom\n0\n38\n\n\nKai Nurminen\n67\n0\n\n\nKonstantin Shafranov\n5\n0\n\n\nMagnus Arvedson\n0\n61\n\n\nMarco Sturm\n0\n74\n\n\nMatt Cullen\n0\n61\n\n\nMatt Higgins\n0\n1\n\n\nOlli Jokinen\n0\n8\n\n\nPatrick Marleau\n0\n74\n\n\nPavel Kubina\n0\n10\n\n\nRonnie Sundin\n0\n1\n\n\nRuslan Salei\n30\n66\n\n\nSergei Samsonov\n0\n81\n\n\nTravis Brigley\n0\n2\n\n\n\nTable 3.4.1: Players with games in 1996-1997 and/or 1997-1998\n\n\n\n\n\n\n\n\nI checked all of the names in Figure 3.4.1 manually and it turns out that the Jeff Brown listed is not the Jeff Brown that was drafted in 1996, so he should be excluded (the Jeff Brown drafted in 1996 played in 0 career NHL games). All other players are correct. We see the summarized totals below in Figure 3.4.2:\n\n\nCode\nold_ps_players |&gt; \n  filter(player != \"Jeff Brown\") |&gt; # remove the other Jeff Brown\n  pivot_longer(cols = c(gp_1997, gp_1998), \n               names_to = \"year\", \n               values_to = \"gp\") |&gt; # put data in long format to summarize\n  group_by(year) |&gt; \n  summarize(total_gp = sum(gp), \n            n = length(which(gp &gt; 0))) |&gt; \n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 3.4.2: Totals of Players in our Dataset\") |&gt;\n  cols_label(total_gp = \"total games\", n = \"number of players\") |&gt; \n  sub_values(values = \"gp_1997\", replacement = \"1997\") |&gt;   \n  sub_values(values = \"gp_1998\", replacement = \"1998\")\n\n\n\n\n\n\n\n\nyear\ntotal games\nnumber of players\n\n\n\n\n1997\n290\n6\n\n\n1998\n1066\n26\n\n\n\nTable 3.4.2: Totals of Players in our Dataset\n\n\n\n\n\n\n\n\nFigure 3.4.2 shows that a very small proportion of the players in our dataset (approximately 5400 players) played games under the old PS formula and that these games represent an insignificant proportion of the games in our dataset (there are 774,820 games in total, the old PS games represent about 0.175% of these). Thus we can see that the different PS formulas is not a major concern and is unlikely to significantly impact our results.\nNote also that we will also use GP (games played) as a measure of player success, and that there have been 82 games per regular season for most NHL seasons since 1996 (2004-2005 was cancelled, 2012-2013, 2019-2020, and 2020-2021 were shortened to 48 games, between 68-71 games, and 56 games, respectively). It is unlikely these will meaningfully affect our results given how many games are in our dataset. We can now proceed to the Tidy step.\n\n\n\n\nMoreau, Ryker, Harsha Perera, and Tim Swartz. 2025. “Valuation of NHL Draft Picks Using Functional Data Analysis - Ryker Moreau, Harsha Perera, Tim B Swartz, 2025.” https://journals.sagepub.com/doi/10.1177/22150218251324875.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "tidy.html",
    "href": "tidy.html",
    "title": "4  Tidy",
    "section": "",
    "text": "4.1 Setup\nWe install and load the necessary packages, along with functions from prior chapters.\nCode\n# renv::install(\"rvest\")\n# renv::install(\"tidyverse\")\n# renv::install(\"gt\")\n# renv::install(\"DBI\")\n# renv::install(\"duckdb\")\n# renv::install(\"aws.s3\")\n# renv::install(\"paws\")\n# renv::install(\"arrow\")\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(gt)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(aws.s3)\nlibrary(paws)\nlibrary(arrow)\n\nsource(\"functions.R\") # load functions defined in prior chapters",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "tidy.html#introduction",
    "href": "tidy.html#introduction",
    "title": "4  Tidy",
    "section": "4.2 Introduction",
    "text": "4.2 Introduction\nIn the Tidy chapyer, we will put the data into tidy form, clean it, and store it in an S3 bucket, which will make our analysis in the following chapters easier. Despite the table from the previous chapter looking fairly clean, further inspection reveals some issues, as shown in Figure 4.2.1:\n\n\nCode\nstart_year &lt;- 1996\nend_year &lt;- 2020\n\nimport_draft(start_year)[23:30,] |&gt; # picks 23-28\n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 4.2.1: Some Issues in our Data\")\n\n\n\n\n\n\n\n\noverall\nteam\nplayer\nnat\npos\nage\nto\namateur_team\ngp\ng\na\npts\nx\npim\ngp_2\nw\nl\nt_o\nsv_percent\ngaa\nps\n\n\n\n\n23\nPittsburgh Penguins\nCraig Hillier\nCA\nG\n\n\nOttawa 67's (OHL)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n24\nPhoenix Coyotes\nDaniel Briere\nCA\nC\n18\n2015\nDrummondville Voltigeurs (QMJHL)\n973\n307\n389\n696\n-24\n744\n\n\n\n\n\n\n78.5\n\n\n25\nColorado Avalanche\nPeter Ratchuk\nUS\nD\n19\n2001\nShattuck-St. Mary's School (High-MN)\n32\n1\n1\n2\n-2\n10\n\n\n\n\n\n\n0.6\n\n\n26\nDetroit Red Wings\nJesse Wallin\nCA\nD\n18\n2003\nRed Deer Rebels (WHL)\n49\n0\n2\n2\n-5\n34\n\n\n\n\n\n\n0.2\n\n\n\nRound 2\nRound 2\n\n\n\n\n\nNHL Scoring Stats\nNHL Scoring Stats\nNHL Scoring Stats\nNHL Scoring Stats\nNHL Scoring Stats\nNHL Scoring Stats\nNHL Goalie Stats\nNHL Goalie Stats\nNHL Goalie Stats\nNHL Goalie Stats\nNHL Goalie Stats\nNHL Goalie Stats\n\n\n\nOverall\nTeam\nPlayer\nNat.\nPos\nAge\nTo\nAmateur Team\nGP\nG\nA\nPTS\n+/-\nPIM\nGP\nW\nL\nT/O\nSV%\nGAA\nPS\n\n\n27\nBuffalo Sabres\nCory Sarich\nCA\nD\n18\n2014\nSaskatoon Blades (WHL)\n969\n21\n137\n158\n-9\n1089\n\n\n\n\n\n\n36.0\n\n\n28\nPittsburgh Penguins\nPavel Skrbek\nCZ\nD\n18\n2002\nHC Kladno (Czech)\n12\n0\n0\n0\n1\n8\n\n\n\n\n\n\n0.2\n\n\n\nTable 4.2.1: Some Issues in our Data\n\n\n\n\n\n\n\n\nSome problems that immediately come up are:\n\nTwo rows get inserted at the end of every round to indicate the round changed.\nThough not visible because of the usage of gt, numbers are being coded as strings (overall, age, to, etc).\n(At least) one player is missing everything except for their pick number, name, team, position, nationality, and amateur team.\nThe +/- column got renamed to x.\nThere were two gp columns, one got automatically renamed to gp2 when we used janitor::clean_names() in import_draft.\n\nBy doing a little bit of detective work with some of the other players with missing values elsewhere in the dataset, we notice that players who never played in the NHL have empty strings listed for everything except for their pick number, name, team, position, nationality, and amateur team. This is one of several things we will do in the Tidy chapter to prepare our data for analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "tidy.html#cleaning",
    "href": "tidy.html#cleaning",
    "title": "4  Tidy",
    "section": "4.3 Cleaning",
    "text": "4.3 Cleaning\nWe build a function to tidy the data. In particular, we want it to:\n\nRemove the rows added between rounds.\nCorrect the types of each column so we can use numeric columns in calculations.\nChange gp and ps values to 0 for players who never played in the NHL or have a negative ps.\nStandardize position to either be F (forward, any combination of LW, RW, C), D (defenceman), or G (goalie). Note that Kaspars Astashenko has his position listed as “D/W”, a quick search of the NHL website reveals he was a defenceman.\nIf is.na(to), then the player never played in the NHL, so set it to the draft year.\nAdd a year column so we can combine all of the data into a single data frame.\nSelect the columns we care about (year, overall, pos, to, ps, and gp) in that order.\nRemove any players selected after 224\\(^{\\text{th}}\\) overall (the number of picks in the 2025 NHL Entry Draft).\nWe don’t care about +/-, so we can ignore the column being renamed since we won’t be using it anyway.\nIt also turns out that for skaters gp2 is empty and for goalies gp and gp2 will have the same value, so this issue can be resolved by simply selecting gp.\nThe 69\\(^{\\text{th}}\\) pick of 2011 was forfeited and and 123\\(^{\\text{rd}}\\) pick of 2002 was invalid; both are listed as blank rows, so these should be removed.\n\nNote that we cannot remove the round separating rows by removing a specified row number since many of the drafts in our dataset have different numbers of picks per round, and some rounds within the same draft have even had a different numbers of picks.\n\n\nCode\ntidy_draft &lt;- function(year){\n  draft_year_table &lt;- import_draft(year) |&gt; # get the untidied data\n    filter(overall != \"Overall\" & overall != \"\" & # remove extra rows\n             as.numeric(overall) &lt; 225 & # remove players drafted after pick 224\n             amateur_team != \"()\") |&gt; # remove invalid/forfeited picks \n    type_convert() |&gt; # fix types \n    mutate(\"year\" = year, \n           \"ps\" = pmax(coalesce(ps, 0), 0), \"gp\" = coalesce(gp, 0), # players who never played in the NHL\n           \"to\" = coalesce(to, year), # players who never played in the NHL\n           \"pos\" = ifelse(str_count(pos, \"G\") == 1, \"G\", # fix positions\n                          ifelse(str_count(pos, \"D\") == 1, \"D\", \"F\"))) |&gt; \n    select(year, overall, to, pos, ps, gp) # columns we care about\n  draft_year_table\n}\n\ntidy_draft(1996) |&gt; \n  head(50) |&gt; \n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 4.3.1: The Function Works Correctly\")\n\n\n\n\n\n\n\n\nyear\noverall\nto\npos\nps\ngp\n\n\n\n\n1996\n1\n2015\nD\n64.6\n1179\n\n\n1996\n2\n2008\nD\n25.8\n496\n\n\n1996\n3\n2011\nF\n56.6\n822\n\n\n1996\n4\n2000\nF\n0.0\n3\n\n\n1996\n5\n2007\nD\n8.8\n231\n\n\n1996\n6\n2009\nF\n12.5\n627\n\n\n1996\n7\n2007\nF\n9.2\n545\n\n\n1996\n8\n2004\nD\n0.0\n44\n\n\n1996\n9\n2011\nD\n46.9\n917\n\n\n1996\n10\n2004\nD\n2.7\n209\n\n\n1996\n11\n2004\nD\n0.0\n82\n\n\n1996\n12\n2004\nF\n0.6\n60\n\n\n1996\n13\n2014\nD\n74.6\n1107\n\n\n1996\n14\n2013\nF\n17.7\n798\n\n\n1996\n15\n2016\nF\n52.0\n1293\n\n\n1996\n16\n1999\nD\n0.0\n5\n\n\n1996\n17\n2000\nF\n3.5\n113\n\n\n1996\n18\n2001\nF\n0.0\n57\n\n\n1996\n19\n2001\nD\n0.3\n5\n\n\n1996\n20\n2008\nF\n12.8\n521\n\n\n1996\n21\n2012\nF\n54.0\n938\n\n\n1996\n22\n1996\nD\n0.0\n0\n\n\n1996\n23\n1996\nG\n0.0\n0\n\n\n1996\n24\n2015\nF\n78.5\n973\n\n\n1996\n25\n2001\nD\n0.6\n32\n\n\n1996\n26\n2003\nD\n0.2\n49\n\n\n1996\n27\n2014\nD\n36.0\n969\n\n\n1996\n28\n2002\nD\n0.2\n12\n\n\n1996\n29\n2009\nF\n0.0\n337\n\n\n1996\n30\n2012\nF\n5.1\n341\n\n\n1996\n31\n1999\nD\n0.0\n18\n\n\n1996\n32\n2004\nD\n0.0\n6\n\n\n1996\n33\n1996\nF\n0.0\n0\n\n\n1996\n34\n1996\nF\n0.0\n0\n\n\n1996\n35\n2019\nF\n66.0\n1516\n\n\n1996\n36\n2001\nD\n0.6\n19\n\n\n1996\n37\n2002\nF\n2.6\n73\n\n\n1996\n38\n1996\nF\n0.0\n0\n\n\n1996\n39\n2004\nF\n0.0\n55\n\n\n1996\n40\n2013\nF\n6.6\n524\n\n\n1996\n41\n1996\nD\n0.0\n0\n\n\n1996\n42\n2003\nD\n0.0\n2\n\n\n1996\n43\n2007\nF\n22.0\n552\n\n\n1996\n44\n2013\nG\n49.0\n341\n\n\n1996\n45\n1996\nF\n0.0\n0\n\n\n1996\n46\n1996\nF\n0.0\n0\n\n\n1996\n47\n2006\nF\n7.3\n142\n\n\n1996\n48\n2000\nF\n0.7\n53\n\n\n1996\n49\n2012\nD\n42.1\n797\n\n\n1996\n50\n1996\nG\n0.0\n0\n\n\n\nTable 4.3.1: The Function Works Correctly\n\n\n\n\n\n\n\n\nFigure 4.3.1 confirms the function completes the tasks listed at the start of this section. We can now proceed to import the data, we choose to clean it as we import it.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "tidy.html#getting-the-data",
    "href": "tidy.html#getting-the-data",
    "title": "4  Tidy",
    "section": "4.4 Getting the Data",
    "text": "4.4 Getting the Data\nWe now load in all of the data and use rbind() to bind the tables together, giving us a single data frame to work with. This also means that our data will be in a mix of long and wide format, since the year and overall columns are formatted like they are in long format but the to, pos, gp, and ps columns are the same as they would be in a wide format. Note that this function takes 2-3 minutes to run (because of the Sys.sleep(5) line, which is necessary to prevent us getting rate limited). We will soon store the data in a S3 bucket so we don’t have to run this function any more than we have to.\n\n\nCode\nall_data &lt;- do.call(rbind, lapply(seq(start_year, end_year, 1),\n                   \\(x) tidy_draft(x)))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "tidy.html#verification",
    "href": "tidy.html#verification",
    "title": "4  Tidy",
    "section": "4.5 Verification",
    "text": "4.5 Verification\nWe can check that we loaded the data correctly, there should be between 5250 and 5600 rows (the number of picks in a draft has changed over the years in our dataset as we will see, but is always between 210 and 224 so 25 drafts will be between ) and 6 columns:\n\n\nCode\ndim(all_data) # confirm there are 5250-5600 rows and 6 columns\n\n\n[1] 5425    6\n\n\nCode\nlength(unique(all_data$year)) # confirm all 25 years have been included\n\n\n[1] 25\n\n\nCode\n# should be the last 10 picks from 2020, note that there were 7*31 = 217 \n#   picks in the draft that year\nall_data |&gt;\n  tail(10) |&gt;\n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"Table 4.4.1: The Last 10 Picks from our Dataset\")\n\n\n\n\n\n\n\n\nyear\noverall\nto\npos\nps\ngp\n\n\n\n\n2020\n208\n2020\nD\n0.0\n0\n\n\n2020\n209\n2020\nF\n0.0\n0\n\n\n2020\n210\n2020\nF\n0.0\n0\n\n\n2020\n211\n2020\nF\n0.0\n0\n\n\n2020\n212\n2025\nG\n5.7\n39\n\n\n2020\n213\n2020\nF\n0.0\n0\n\n\n2020\n214\n2020\nG\n0.0\n0\n\n\n2020\n215\n2020\nF\n0.0\n0\n\n\n2020\n216\n2020\nF\n0.0\n0\n\n\n2020\n217\n2020\nF\n0.0\n0\n\n\n\nTable 4.4.1: The Last 10 Picks from our Dataset\n\n\n\n\n\n\n\n\nCode\nall_data |&gt; # Confirm pick 123 of 2002 was removed (it was an invalid pick)\n  filter(year == 2002 & overall &lt;= 125 & overall &gt;= 121) |&gt; \n  gt() |&gt; \n  opt_all_caps() |&gt; \n  tab_source_note(\"4.4.2: Pick 123 in 2002 was Removed\")\n\n\n\n\n\n\n\n\nyear\noverall\nto\npos\nps\ngp\n\n\n\n\n2002\n121\n2002\nG\n0\n0\n\n\n2002\n122\n2002\nD\n0\n0\n\n\n2002\n124\n2002\nD\n0\n0\n\n\n2002\n125\n2002\nD\n0\n0\n\n\n\n4.4.2: Pick 123 in 2002 was Removed\n\n\n\n\n\n\n\n\nThese checks all returned what they should.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "tidy.html#storing-the-data",
    "href": "tidy.html#storing-the-data",
    "title": "4  Tidy",
    "section": "4.6 Storing the Data",
    "text": "4.6 Storing the Data\nFinally, recall that the import_data function (and thus the tidy_draft function) both take quite a while to run, especially when importing data for a large number of years. To resolve this issue, we will store the data in an AWS S3 bucket so future chapters can get the data from the S3 bucket instead of from Hockey Reference, making this report render significantly faster. We do this by following the instructions given by Agarwal (2020), which tell us to save all_data in parquet file and then write it to our S3 bucket.\n\n\nCode\nSys.setenv(\"AWS_ACCESS_KEY_ID\" = Sys.getenv(\"AWS_ACCESS_KEY_ID\"),\n           \"AWS_SECRET_ACCESS_KEY\" = Sys.getenv(\"AWS_SECRET_ACCESS_KEY\"), \n           \"AWS_DEFAULT_REGION\" = \"us-east-2\")\nbucket = \"trevor-stat468\"\n\ns3write_using(all_data, FUN = write_parquet, \n              bucket = bucket, object = \"all_data.parquet\")\n\n\nIn this and future chapters, we still start by loading in all of the functions from functions.R, which includes all the functions and global constants defined in all chapters, in addition to querying the data from the AWS S3 bucket using duckdb. functions.R is included in this project’s GitHub repo, and the part of it that loads all_data is also given below (here we load it into all_data_test to show that it actually works). I also followed some of the instructions from Michonneau (2023) to help me write the below code.\n\n\nCode\ncon &lt;- dbConnect(duckdb())\n\ndbExecute(con, \"INSTALL httpfs;\")\ndbExecute(con, \"LOAD httpfs;\")\n\nall_data_test &lt;- dbGetQuery(con, \"SELECT * \n                            FROM read_parquet('s3://trevor-stat468/all_data.parquet');\")\n\nDBI::dbDisconnect(con)\n\n\n\n\nCode\ndim(all_data_test)\n\n\n[1] 5425    6\n\n\nCode\nall_data_test |&gt; \n  head(10) |&gt; \n  gt() |&gt;\n  opt_all_caps() |&gt; \n  tab_source_note(\"4.6.1: Data Loaded from S3 Bucket\")\n\n\n\n\n\n\n\n\nyear\noverall\nto\npos\nps\ngp\n\n\n\n\n1996\n1\n2015\nD\n64.6\n1179\n\n\n1996\n2\n2008\nD\n25.8\n496\n\n\n1996\n3\n2011\nF\n56.6\n822\n\n\n1996\n4\n2000\nF\n0.0\n3\n\n\n1996\n5\n2007\nD\n8.8\n231\n\n\n1996\n6\n2009\nF\n12.5\n627\n\n\n1996\n7\n2007\nF\n9.2\n545\n\n\n1996\n8\n2004\nD\n0.0\n44\n\n\n1996\n9\n2011\nD\n46.9\n917\n\n\n1996\n10\n2004\nD\n2.7\n209\n\n\n\n4.6.1: Data Loaded from S3 Bucket\n\n\n\n\n\n\n\n\nFigure 4.6.1 confirms that the data can be loaded from the S3 bucket. In future chapters we will edit this data and will put the new version in the same S3 bucket. We now proceed to the Visualize chapter.\n\n\n\n\nAgarwal, Saurabh. 2020. “How to Read and Write Data from and to S3 Bucket Using R?” Medium. https://medium.com/@som028/how-to-read-and-write-data-from-and-to-s3-bucket-using-r-3fed7e686844.\n\n\nMichonneau, François. 2023. “How to Work with Remote Parquet Files with the Duckdb R Package?” https://francoismichonneau.net/2023/06/duckdb-r-remote-data/.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tidy</span>"
    ]
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "5  Visualize",
    "section": "",
    "text": "5.1 Setup\nWe install and load the necessary packages, along with functions and data from prior chapters.\nCode\n# renv::install(\"gt\")\n# renv::install(\"ggplot2\")\n# renv::install(\"patchwork\")\n\nlibrary(gt)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nsource(\"functions.R\") # load functions defined in prior chapters",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualize</span>"
    ]
  },
  {
    "objectID": "visualize.html#introduction",
    "href": "visualize.html#introduction",
    "title": "5  Visualize",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction\nIn the visualize step, we will perform some EDA (Exploratory Data Analysis) to get a sense of what our data looks like. Specifically, we will see if there are any patterns or trends that may be useful in the Model chapter.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualize</span>"
    ]
  },
  {
    "objectID": "visualize.html#exploratory-data-analysis-eda",
    "href": "visualize.html#exploratory-data-analysis-eda",
    "title": "5  Visualize",
    "section": "5.3 Exploratory Data Analysis (EDA)",
    "text": "5.3 Exploratory Data Analysis (EDA)\n\n5.3.1 Number of Picks\nRecall that over the years the NHL has changed how many picks there are in each round as franchises have been added. A consequence of this is that the number of rounds has also changed, and the number of total picks in a draft has changed several times throughout our dataset. Recall that we removed all picks after #224, but there could be drafts with fewer than 224 total selections. We check for this:\n\n\nCode\nall_data |&gt; \n  group_by(year) |&gt; \n  summarize(num_picks = n()) |&gt; \n  ggplot(aes(x = year, y = num_picks)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nIndeed the drafts after 2005 all have fewer than 224 selections. Note also that 2002 had an invalid pick and 2011 had a forfeited pick, neither is included in this. Some drafts having fewer pick is not a major problem since very late picks aren’t worth very much anyway, but it is worth noting that several picks from #211 onward have a smaller sample size than picks 1-210.\n\n\n5.3.2 PS and GP Values\nBefore doing any further EDA, we will take the five number summary, mean, and standard deviation of both the GP and PS values to get a sense of what they look like. Recall that the five number summary gives the minimum, 25% quantile, median, 75% quantile, and maximum of a dataset. Additionally, recall that PS stands for Point Share, and is a measure of a player’s career contributions to points in the standings (ie the points you get from wins, not the one that is goals plus assists).\n\n\nCode\nc(\"five num\" = fivenum(all_data$gp), \"mean\" = mean(all_data$gp), \"sd\" = sd(all_data$gp))\n\n\nfive num1 five num2 five num3 five num4 five num5      mean        sd \n   0.0000    0.0000    0.0000  145.0000 1779.0000  142.8240  274.0671 \n\n\nCode\nc(\"five_num\" = fivenum(all_data$ps), \"mean\" = mean(all_data$ps), \"sd\" = sd(all_data$ps))\n\n\n five_num1  five_num2  five_num3  five_num4  five_num5       mean         sd \n  0.000000   0.000000   0.000000   3.000000 217.800000   8.252903  21.185903 \n\n\nClearly both the GP and PS values are right skewed. Note that the maximum of the GP data is around 6 standard deviations from the mean \\((\\frac{1779-142.7713}{274.0303} = 5.97)\\) , whereas the maximum of the PS data is almost 10 standard deviations away \\((\\frac{217.8-8.249862}{21.172591} = 9.89)\\).\nWe next check what proportion of our dataset ever played in an NHL game and what proportion generated more than 2 PS in their career, which is the value of exactly one win in the NHL. Based on the research of Luo (2024), we also plan to create a metric based on the proportion of players in our dataset who played in less than 200 NHL games (note that in the Transfom chapter we will use a slightly different metric for active players and goalies, but since we are just exploring the data this will be sufficient for now).\n\n\nCode\nall_data |&gt; \n  filter(gp &gt; 0) |&gt; \n  nrow() / nrow(all_data)\n\n\n[1] 0.4812903\n\n\nCode\nall_data |&gt; \n  filter(ps &gt; 2) |&gt; \n  nrow() / nrow(all_data)\n\n\n[1] 0.2709677\n\n\nCode\nall_data |&gt; \n  filter(gp &gt;= 200) |&gt; \n  nrow() / nrow(all_data)\n\n\n[1] 0.2171429\n\n\nThis tells us that just over half of our dataset never played in an NHL game, almost three quarters made minimal on-ice contributions in their career, and that approximately 20% of our dataset played in at least 200 NHL games.\nTo get visual confirmation that our data is very right skewed, we check the histograms of the data, one of GP (on the left) and one of PS (on the right). We also set the scales to be the same to make comparing the values easier.\n\n\nCode\ngp_hist &lt;- all_data |&gt; \n  ggplot(aes(gp)) + \n  geom_histogram() + \n  scale_y_continuous(limits = c(0, 4200)) + \n  labs(title = \"Distribution of GP\", \n       x = \"GP\", y = \"Number of Players\") \n\nps_hist &lt;- all_data |&gt; \n  ggplot(aes(ps)) + \n  geom_histogram() + \n  scale_y_continuous(limits = c(0, 4200)) + \n  labs(title = \"Distribution of PS\", \n       x = \"PS\", y = \"Number of Players\") \n\ngp_hist + ps_hist\n\n\n\n\n\n\n\n\n\nIndeed, both of these are very right-skewed, and clearly a lot of players end up playing a small number of games and are thus not generating able to generate much PS. The fact that there are more players with a small PS than a small GP also makes sense since players could be unproductive in ~75 games, which would take them out of the first bin for GP while they remain ib the first bin for PS.\n\n\n5.3.3 Picking a Metric\nWe may also guess that GP and PS are positively correlated, since better players get to play in more games and thus accumulate more PS. Indeed:\n\n\nCode\ncor(all_data$ps, all_data$gp)\n\n\n[1] 0.8558304\n\n\nThe relationship is very clear when we split the points by position. The first plot is good because it makes comparing points easier, the other three are nice because they are less crowded.\n\n\nCode\nplot_comb &lt;- ggplot(all_data, aes(x = gp, y = ps, col = pos)) + \n  geom_point(alpha = 0.35)\n\nplot_facet &lt;-  ggplot(all_data, aes(x = gp, y = ps)) + \n  geom_point(alpha = 0.25) + \n  facet_wrap(~pos)\n\nplot_comb / plot_facet\n\n\n\n\n\n\n\n\n\nI suspect this strong correlation (especially for goalies) is largely because players who are good and get lots of PS play for longer and thus play in more GP. Because of this, we choose to only include one of GP and PS in each model to avoid multicollinearity concerns. As mentioned in the Approach section, we will use two GP-related metrics and two PS-related metrics. For each of these metrics we will fit a linear and non-linear regression model, for a total of 8 models. We now explore the GP and PS values in greater detail.\n\n\n5.3.4 GP and PS of Draft Classes\nWe wish to confirm that players selected earlier in a draft (ie a lower overall) tend to play in more games and generate more PS during their careers than those selected later. To check this, we start by creating plot of the GP and PS values by overall for a single draft. Note we will use scales = \"free\" because the scales of GP and PS are quite different:\n\n\nCode\nset.seed(468) # for reproducibility\nrand_year &lt;- sample(start_year:end_year, 1) # year is 2015\n\ngp_plot_1 &lt;- all_data |&gt; \n  filter(year == rand_year) |&gt; \n  ggplot(aes(x = overall, y = gp)) +\n  geom_point() +\n  labs(x = \"Pick Number\", y = \"GP\", \n       title = str_glue(\"GP of Players Drafted in {rand_year}\"), \n       subtitle = \"Note the plots have different scales\")\n\nps_plot_1 &lt;- all_data |&gt; \n  filter(year == rand_year) |&gt; \n  ggplot(aes(x = overall, y = ps)) +\n  geom_point() +\n  labs(x = \"Pick Number\", y = \"PS\", \n       title = str_glue(\"PS of Players Drafted in {rand_year}\"), \n       subtitle = \"Note the plots have different scales\")\n\ngp_plot_1 + ps_plot_1\n\n\n\n\n\n\n\n\n\nSince clearly so many players play in 0 games and thus generate 0 PS, we will recreate the plot without the players that played in 0 NHL games to make the plot easier to read. This time we will include multiple drafts.\n\n\nCode\ngp_plot_2 &lt;- all_data |&gt; \n  filter(gp &gt; 0) |&gt; \n  ggplot(aes(x = overall, y = gp)) + \n  geom_point(alpha = 0.5) + \n  labs(title = \"Distribution of GP\",\n       subtitle = \"Players with ≥ 1 game only; \\nnote the plots have different scales\", \n       x = \"Pick Number\", y = \"GP\")\n\nps_plot_2 &lt;- all_data |&gt; \n  filter(gp &gt; 0) |&gt; \n  ggplot(aes(x = overall, y = ps)) + \n  geom_point(alpha = 0.5) + \n  labs(title = \"Distribution of PS\",\n       subtitle = \"Players with ≥ 1 game only; \\nnote the plots have different scales\", \n       x = \"Pick Number\", y = \"PS\")\n\ngp_plot_2 + ps_plot_2\n\n\n\n\n\n\n\n\n\nThese plots are quite dense and difficult to interpret, but there isn’t really any point in jittering the data because it’ll still overlap, so we re plot them with a random 5 year sample of our dataset.\n\n\nCode\nyears &lt;- sample(start_year:end_year, 5) # years are 2018, 1996, 1999, 2010, 2004\n\ngp_plot_3 &lt;- all_data |&gt; \n  filter(gp &gt; 0 & year %in% years) |&gt; \n  ggplot(aes(x = overall, y = gp)) + \n  geom_point(alpha = 0.5) + \n  labs(title = \"Distribution of GP for 5 Drafts\",\n       subtitle = \"Players with ≥ 1 game only; \\nnote the plots have different scales\", \n       x = \"Pick Number\", y = \"GP\")\n\nps_plot_3 &lt;- all_data |&gt; \n  filter(gp &gt; 0 & year %in% years) |&gt; \n  ggplot(aes(x = overall, y = ps)) + \n  geom_point(alpha = 0.5) + \n  labs(title = \"Distribution of PS for 5 Drafts\",\n       subtitle = \"Players with ≥ 1 game only; \\nnote the plots have different scales\", \n       x = \"Pick Number\", y = \"PS\")\n\ngp_plot_3 + ps_plot_3 \n\n\n\n\n\n\n\n\n\nThough these plot are still quite busy, it shows a strange trend that there seems to be more players drafted around 200 overall that end up having successful careers, than drafted around 125. I am not sure of an underlying reason for this, but we will need to be careful when modeling to ensure that these late picks are not given more value than earlier picks.\nThe plots above are not great because they are missing the vast majority of our dataset (20 drafts plus all the players who played in 0 NHL games for the 5 years in the sample). To improve this, we plot the mean GP and mean PS of the players selected at each pick. We will use the non-aggregated PS and GP values when fitting a model, but the relationship between Overall and PS or GP is more clear when the values are averaged.\n\n\nCode\ngp_plot_4 &lt;- all_data |&gt; \n  group_by(overall) |&gt; \n  summarize(mean_gp = mean(gp)) |&gt; \n  ggplot(aes(x = overall, y = mean_gp)) + \n  geom_point() +\n  geom_point(aes(x = 156, y = mean(filter(all_data, overall==156)$gp)), col = \"dodgerblue\") +\n  geom_point(aes(x = 205, y = mean(filter(all_data, overall==205)$gp)), col = \"salmon\") +\n  labs(title = \"Mean GP by Pick Number\", subtitle = \"Note the scales are different\",\n       x = \"Pick Number\", y = \"Mean GP\") + \n  annotate(geom = \"segment\", x = 156, y = 450, xend = 156, yend = 220, colour = \"dodgerblue\",\n    arrow = arrow(type = \"open\", length = unit(0.32, \"cm\"))) +\n  annotate(geom = \"label\", x = 90, y = 400,\n    label = \"156th overall selection,\\n(mean GP of 203)\",\n    hjust = \"left\", colour = \"dodgerblue\")\n\nps_plot_4 &lt;- all_data |&gt; \n  group_by(overall) |&gt; \n  summarize(mean_ps = mean(ps)) |&gt; \n  ggplot(aes(x = overall, y = mean_ps)) + \n  geom_point() +\n  geom_point(aes(x = 156, y = mean(filter(all_data, overall==156)$ps)), col = \"dodgerblue\") +\n  geom_point(aes(x = 205, y = mean(filter(all_data, overall==205)$ps)), col = \"salmon\") +\n  labs(title = \"Mean PS by Pick Number\", subtitle = \"Note the scales are different\",\n       x = \"Pick Number\", y = \"Mean PS\") + \n  annotate(geom = \"segment\", x = 175, y = 37.5, xend = 203, yend = 14, colour = \"salmon\",\n    arrow = arrow(type = \"open\", length = unit(0.32, \"cm\"))) +\n  annotate(geom = \"label\", x = 100, y = 39,\n    label = \"205th overall selection,\\n(mean PS of 13.124)\",\n    hjust = \"left\", colour = \"salmon\")\n\ngp_plot_4 + ps_plot_4\n\n\n\n\n\n\n\n\n\nInterestingly, points that appear to be outliers in mean GP may not be outliers in mean PS (and vise versa). This is indicated by the blue and pink points in each plot. We can also see that in general GP and PS both tend to decrease later in drafts, and that pick value tends to level off around pick 75, though there are some picks that stick out (for example, pick 205 has an average PS of 13.124, whereas pick 204 has an average PS of 4.856). This particular outlier is due to Henrik Lundqvist and Joe Pavelski being selected at this spot and having career PSs of 173.3 and 130.1, respectively. Very few players drafted this late make it to the NHL (20 of the 25 players in our dataset drafted at pick 205 have more than 0.3 PS), so two players with very successful careers skewing the GP and PS data is not surprising.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualize</span>"
    ]
  },
  {
    "objectID": "visualize.html#summary",
    "href": "visualize.html#summary",
    "title": "5  Visualize",
    "section": "5.4 Summary",
    "text": "5.4 Summary\nWe take the following lessons from our EDA into our Transform and Model chapters:\n\nEach model should only use one of GP or PS to avoid multicollinearity-related issues.\nWe will need to fit a curve or line to the data, since if we simply set \\(v_i\\) to be the mean GP or PS of players selected at pick \\(i\\) then we will fail the first fundamental requirement, that \\(v_i &gt; v_{i+k}\\) for all \\(i, k \\in \\mathbb Z^+\\).\n\nThe GP by pick number and PS by pick number metrics are two of the metrics we will use in the Model chapter.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Visualize</span>"
    ]
  },
  {
    "objectID": "transform.html",
    "href": "transform.html",
    "title": "6  Transform",
    "section": "",
    "text": "6.1 Setup\nWe install and load the necessary packages, along with functions and data from prior chapters.\nCode\n# renv::install(\"tidyverse\")\n# renv::install(\"dplyr\")\n# renv::install(\"gt\")\n# renv::install(\"reactable\")\n# renv::install(\"patchwork\")\n# renv::install(\"stringr\")\n\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(reactable)\nlibrary(patchwork)\nlibrary(stringr)\n\nsource(\"functions.R\") # load functions defined in prior chapters",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "transform.html#introduction",
    "href": "transform.html#introduction",
    "title": "6  Transform",
    "section": "6.2 Introduction",
    "text": "6.2 Introduction\nAt the end of the Visualize step we looked at the mean GP and mean PS of players selected at pick \\(i\\). These are the first two of the four metrics that will be used to fit a model in the Model chapter. In the Transform chapter, we will create the other two metrics. First, we will implement the method taken by Luo (2024) which is to define a draft pick to be a “success” if that prospect becomes an NHL regular, which is defined to be playing in \\(\\ge\\) 200 NHL games for skaters. We will then look at the success rate of each pick number for the drafts in our dataset. That is, we will set \\(p_i = \\frac{\\text{number of successfull picks at pick $i$}}{\\text{number of $i^{th}$ overall picks}}\\) . Recall in our EDA section we mentioned that some drafts had fewer than 224 selections, which is why we divide by the number of \\(i^{th}\\) overall picks instead of always dividing by 25. Note that Luo was using this method for slightly different analysis (he was evaluating prospect quality to better evaluate prospects, not value draft picks), but the general idea is very similar.\nThe other transformation we will make in this step is to adjust our PS to better represent the careers of actve players (ie those who have not retired yet). Recall that in the Visualize chapter we looked at the average PS of all players in out dataset drafted at pick \\(i\\). As mentioned in the constraints section, one problem with this approach is that players drafted more recently will have had fewer years to generate PS. We can see in the plot below that, unsurprisingly, the total PS is quite a bit lower for the drafts between 2016 and 2020:\n\n\nCode\nall_data |&gt; \n  group_by(year) |&gt; \n  summarize(total_ps = sum(ps)) |&gt;\n  ggplot(aes(x = year, y = total_ps)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nConsidering this, it makes sense to make an adjustment to active players based on an estimate of the PS they will generate in the remainder of their career.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "transform.html#transforming-ps",
    "href": "transform.html#transforming-ps",
    "title": "6  Transform",
    "section": "6.3 Transforming PS",
    "text": "6.3 Transforming PS\n\n6.3.1 Introduction\nA similar issue to the one raised above is that there are quite a few current players in our dataset who can still generate additional PS because they are still playing. The issues are related as it is probably reasonable to expect that the discrepancy between the 2016-2020 PS totals and the other years is at least partially due to there being so many active players from those seasons.\n\n\nCode\nall_data |&gt; \n  filter(to == 2025) |&gt; \n  group_by(year) |&gt; \n  summarize(current_players = n()) |&gt;\n  ggplot(aes(x = year, y = current_players)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\nWe can see that our dataset has quite a few active players, and the full value of these players’ careers cannot be fully known. As an aside, it is interesting that PS is so high for the drafts between 2010 and 2015 even though there are still so many active players from those drafts, I did some research but I could not find anything about it. One of my personal theories is that elite players might be skewing things, but Connor McDavid was drafted in 2015 and even he “only” has about 125 PS which is not nearly enough to skew the data on its own. I guess it is possible there were just really strong drafts, but it seems odd that there would be 6 strong drafts in a row.\nEstimating the remaining value of a player’s career could be an entire project all on its own, so we have 3 options:\n\nOnly include drafts from before 2003 (there are no active NHL players who were drafted in 2002 or earlier).\nIgnore this issue altogether (as if every active player in our dataset retired right now).\nMake some sort of adjustment to the PS values of active players to account for the remainder of their career.\n\nNeither of the first two options are particularly appealing. The first is unideal because of sample size concerns and the changes that have taken place in terms of draft eligibility and strategy since the 1980s (which we would need to include to maintain a sample size of 25). Additionally, the second option is arguably worse because it will severely underestimate the quality of star players drafted in the last few years (elite players can play for 15-20 seasons, so we could be missing three quarters of a player’s career if he was drafted in 2020). Thus the only remaining option is to attempt to estimate the remaining value of a player’s career.\nEstimating the remaining value of a player’s career could be an entire project all on its own, but we will make an adjustment that should reduce the impact of this issue (while acknowledging that we will not completely fix it). Let \\(gp_{ij}\\) and \\(ps_{ij}\\) be the GP and PS of the player drafted at pick \\(i\\) of draft \\(j\\). If the player is retired then no adjustment is required, so we set \\(ps_{ij}^{adj} = ps_{j}\\). If that player has not retired, we will set \\(ps^{adj}_{ij} = ps_{ij} + \\frac{ps_{ij}}{gp_{ij}} \\times \\hat{gr_j}\\), where \\(\\hat {gr_j}\\) is our estimate of the number of games left in the career of players drafted in year \\(j\\). We will set \\(\\hat{gr_j} = \\frac{gp_{ij}}{years_{ij}} \\cdot \\hat{yr_j}\\), where \\(years_{ij}\\) is the number of years since player \\(ij\\) was drafted and \\(\\hat{yr_j}\\) is the estimated number of years left in their career. Thus the estimated number of games remaining in a player’s career is their average number of games per season times the estimated number of years remaining. Simplifying, we have \\(ps_{ij}^{adj} = ps_{ij} + \\frac{ps_{ij}}{years_{ij}} \\cdot\\hat{yr_{ij}}\\). We will estimate \\(yr_j\\) later using data from 1996-2004. When we code this adjustment later in this chapter we will verify that the PS values of drafts with a large number of active players end up looking similar to drafts where everyone is retired.\n\n\n6.3.2 Estimating Remaining Career Length\nLet \\(yr_j\\) be the number of years players drafted in draft \\(j\\) have remaining in their career, given they were drafted \\(k\\) years ago. We aim to estimate this value, and will do so by setting \\(\\hat{yr_j}\\) to be the mean career length of players who retired at \\(k\\) years after being drafted and were drafted between 1996 and 2004. We calculate it for \\(1 \\le k \\le 22\\) to make the indexing more intuitive, even though we will only be using the values \\(k \\ge 5\\), since no active player drafted in 2020 or earlier can have played for less than 4 seasons.\n\n\nCode\nget_length &lt;- Vectorize(function(len){ \n  all_data |&gt; \n    mutate(rem_career_len = to - year - len) |&gt; \n    filter(year %in% 1996:2004 & rem_career_len &gt;= 0) |&gt; \n    summarize(mean = mean(rem_career_len)) |&gt; \n    pull(mean)\n})\n\nest_yr &lt;- data.frame(k = seq(1,22)) |&gt;\n  mutate(yr = get_length(k)) \n\nggplot(est_yr, aes(x = k, y = yr)) + \n  geom_point() \n\n\n\n\n\n\n\n\n\nCode\ngt(est_yr)\n\n\n\n\n\n\n\n\nk\nyr\n\n\n\n\n1\n9.477981\n\n\n2\n8.601741\n\n\n3\n7.696370\n\n\n4\n7.004577\n\n\n5\n6.474969\n\n\n6\n6.080107\n\n\n7\n5.716814\n\n\n8\n5.333333\n\n\n9\n4.967093\n\n\n10\n4.720000\n\n\n11\n4.238318\n\n\n12\n3.761155\n\n\n13\n3.382263\n\n\n14\n2.992780\n\n\n15\n2.684444\n\n\n16\n2.212766\n\n\n17\n1.773333\n\n\n18\n1.396396\n\n\n19\n1.214286\n\n\n20\n1.125000\n\n\n21\n1.142857\n\n\n22\n1.000000\n\n\n\n\n\n\n\nThe interpretation for this is that a current NHL player who was drafted 1 year ago has an estimated 9.48 years left in their career, a current NHL player who was drafted 5 years ago has an estimated 6.47 years left in their career, and on.\n\n\n6.3.3 Adjusting PS Values\nNow that we have estimated the remaining number of years for each active NHL player, we can estimate the total PS for their career. Recall that in the introduction of this chapter we said \\(ps_{ij}^{adj} = ps_{ij} + \\frac{ps_{ij}}{years_{ij}} \\cdot\\hat{yr_{ij}}\\).\n\n\nCode\nactive_players &lt;- all_data |&gt; \n  filter(to == 2025) |&gt; \n  mutate(career_len = to - year) |&gt; \n  mutate(adj_ps = ps + round(ps / career_len * get_length(career_len), 2)) |&gt; \n  select(-career_len)\n\ninactive_players &lt;- all_data |&gt; \n  filter(to != 2025) |&gt; \n  mutate(adj_ps = ps)\n\n\nall_data_adj &lt;- rbind(active_players, inactive_players)\nreactable(all_data_adj)\n\n\n\n\n\n\nNote that the adjusted PS values for players who are expected to retire soon may not have changed much, if at all. To say it again, this estimation is not perfect, but it is better than the alternatives (using older data or ignoring the issue). In particular, this method assumes all players will continue to generate PS and play in games at the same rate as they have to this point in their career, and that the number of additional years a player will play for only depends on how many years ago they were drafted.\n\n\n6.3.4 Evaluating our Adjustment\nWe can do some checks to see if these estimates seem reasonable. First, we look at a plot of the PS values before and after the adjustment. We will plot all years for sake of comparison, but recall we only made changes for active players, and thus the drafts between 1996 and 2002 were completely unaffected (and thus the points are on top of each other):\n\n\nCode\nall_data_adj |&gt; \n  group_by(year) |&gt; \n  summarize(total_ps = sum(ps), total_adj_ps = sum(adj_ps)) |&gt;\n  pivot_longer(cols = starts_with(\"total\"), \n               names_to = \"metric\", values_to = \"value\") |&gt; \n  ggplot(aes(x = year, y = value, col = metric)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nIt seems our adjustment was worthwhile since the drafts after 2010 (which are the drafts with a large number of active players) saw their PS values go up substantially.\nNext, we check the magnitude of our changes by calculating the mean and standard deviation of \\(p_{ij}\\) for \\(j \\in \\{ 1996, ..., 2004\\}\\), \\(p_{ij}\\) for \\(j \\in \\{ 2012, ..., 2020 \\}\\), and \\(p_{ij}^{adj}\\) for \\(j \\in \\{ 2012, ..., 2020\\}\\). Note that the intervals are the same size and that the first interval is years where almost all players have retired, and the second interval contains years with more heavily adjusted drafts.\n\n\nCode\nmean_sd &lt;- function(data){\n  c(mean(data), sd(data))\n  }\n  \nmean_sd(filter(all_data_adj, year &lt;= 2004)$ps)\n\n\n[1]  8.806005 23.570904\n\n\nCode\nmean_sd(filter(all_data_adj, year &gt;= 2012)$ps)\n\n\n[1]  6.067517 14.869298\n\n\nCode\nmean_sd(filter(all_data_adj, year &gt;= 2012)$adj_ps)\n\n\n[1]  8.873139 21.217618\n\n\nOur adjustment looks quite good since the mean and standard deviation of the first and third sets seem close, indicating the adjusted PS values for drafts we adjusted “look like” the true PS values. Additionally, the first and second sets look quite different, suggesting that the adjustment we made was necessary.\nAnother way we can check if the adjusted drafts seem similar to the drafts which required little adjustment is by comparing a histogram of the drafts between 1996 and 200 with the drafts between 2016 and 2020. Of course, we’re not expecting them to be perfectly identical because there is a fair amount of variation even between drafts that required little to no adjustment (ex 1999 and 2003).\n\n\nCode\nall_data_adj |&gt; \n  pivot_longer(cols = c(ps,adj_ps), \n               names_to = \"metric\", values_to = \"value\") |&gt; \n  filter((year %in% 1996:2000 & metric == \"ps\") | (year %in% 2016:2020 & metric == \"adj_ps\")) |&gt; \n  ggplot(aes(x = value, fill = metric)) + \n  geom_histogram(position = \"dodge\")\n\n\n\n\n\n\n\n\n\nThese are a bit hard to compare because the tail gets so small so fast, but the values close to 0 look similar enough. We can zoom in on the tail, note that there isn’t much to look at after 100:\n\n\nCode\nall_data_adj |&gt; \n  pivot_longer(cols = c(ps,adj_ps), \n               names_to = \"metric\", values_to = \"value\") |&gt; \n  filter((year %in% 1996:2000 & metric == \"ps\") | (year %in% 2016:2020 & metric == \"adj_ps\")) |&gt; \n  ggplot(aes(x = value, fill = metric)) + \n  geom_histogram(position = \"dodge\") + \n  coord_cartesian(xlim = c(8.5, 100))\n\n\n\n\n\n\n\n\n\nThere seem to be a similar number of observations in each bin, so it seems like our estimations are reasonable. Note again that we are clear restrictions and potential sources of error with this approach, and in the model step we will fit a model using both the raw PS values and the adjusted PS values. Before moving on to the model step, we create a plot of the mean PS and adjusted PS values, which is the same as the last plot from the Visualize chapter, except we will be including the adjusted PS values.\n\n\nCode\nall_data_adj |&gt; \n  pivot_longer(cols = c(ps, adj_ps), names_to = \"metric\", values_to = \"value\") |&gt; \n  group_by(metric, overall) |&gt; \n  summarize(mean_val = mean(value)) |&gt; \n  ggplot(aes(x = overall, y = mean_val, col = metric)) + \n  geom_point(alpha = 0.4)\n\n\n`summarise()` has grouped output by 'metric'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\nThe mean Adjusted PS values are all are greater than or equal to the mean unadjusted PS values, which is to be expected what we would expect because \\(ps^{adj}_{ij} \\ge ps_{ij}\\) as we add PS to players who are still active NHL players and do not change the PS values of retired players. This is the third of the four metrics we will use in the Model chapter, though we will use the raw Adjusted PS values rather than the aggregated values.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "transform.html#transforming-gp",
    "href": "transform.html#transforming-gp",
    "title": "6  Transform",
    "section": "6.4 Transforming GP",
    "text": "6.4 Transforming GP\n\n6.4.1 Introduction\nIn this chapter we will add a column our dataset indicating whether the player became or is on track to become an NHL regular. We will adopt Luo’s definition of an NHL regular being a skater who plays in or is on track to play in 200 games. This is straightforward a player is retired or has already played in enough games, but is more complex if the player is active and has not yet reached the required number of games. For these players, we will take an almost identical approach as Luo (2024), which changes the GP threshold depending on when a player was drafted. The modified threshold for skaters is given below, where \\(j\\) is the year the player was drafted in \\(t_j\\) is the threshold for players drafted in year \\(j\\).\n\\[t_j = \\begin{cases}200 \\text{,                if $j \\le 2017$}\\\\ \\frac{82\\times(2025-j)}{3} \\text{,    if $j \\in \\{ 2018, 2019, 2020 \\}$}\\\\ \\end{cases}\\]\nLuo did not consider goalies at all in his paper, so one of the changes we will make from Luo’s equation is that the threshold for goalies will be \\(\\frac{t_j}{2}\\) because goalies take longer to develop and even the best goalies only play in approximately 75% of their teams’ games. Thus 100 games for a goalie is around 2.5 seasons’ worth, which is roughly equivalent to 200 games for a skater.\nThe only other difference between our threshold is Luo’s is that the years are different, since Luo’s work is from a year ago and used data from slightly different years. Additionally, Luo did some checks to make sure this estimate is appropriate, it turned out to be quite a good predictor of whether a player will play in 200 games. Here is a plot of the skater threshold for games played based on the skater’s draft year.\n\n\n6.4.2 Adding the Indicator\n\n\nCode\nget_threshold &lt;- function(year){  \n  ifelse(year &lt;= 2017, 200, 82/3*(2025-year)) \n} \n\nthresholds &lt;- data.frame(year = seq(2015,2020)) |&gt;    \n  mutate(t = get_threshold(year))  \n\nggplot(thresholds, aes(x = year, y = t)) +    \n  geom_point() +   \n  scale_x_discrete(limits = seq(2015, 2020))\n\n\n\n\n\n\n\n\n\nCode\ngt(thresholds)\n\n\n\n\n\n\n\n\nyear\nt\n\n\n\n\n2015\n200.0000\n\n\n2016\n200.0000\n\n\n2017\n200.0000\n\n\n2018\n191.3333\n\n\n2019\n164.0000\n\n\n2020\n136.6667\n\n\n\n\n\n\n\nWe make this transformation in R, first for retired players, then for active players, and then use rbind ro combine them.\n\n\nCode\nall_data_ret &lt;- all_data_adj |&gt;    \n  filter(to != 2025) |&gt;   \n  mutate(thresh = ifelse(pos == \"G\", 100, 200),           \n         reg = gp &gt;= thresh) |&gt;    \n  select(-thresh)  \n\nall_data_act &lt;- all_data_adj |&gt;    \n    filter(to == 2025) |&gt;    \n  mutate(thresh = ifelse(pos == \"G\", get_threshold(year) / 2,                           \n                         get_threshold(year)),         \n         reg = gp &gt;= thresh) |&gt;    \n  select(-thresh)  \n\nall_data_adj &lt;- rbind(all_data_ret, all_data_act)\n\n\nWe have now added the column necessary to create a model based on whether an NHL player became an NHL regular. We won’t use the aggregated values to fit a model, but to see if this metric has potential we aggregate the data to get the success rate of every pick number and then plot it to ensure the success rate generally decreases ad the draft goes on.\n\n\nCode\nall_data_adj |&gt;    \n  group_by(overall) |&gt;    \n  summarize(rate = mean(reg)) |&gt;    \n  ggplot(aes(x = overall, y = rate)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nThis plot has a similar shape to the plots at the end of the Visualize chapter. We will use the raw TRUE/FALSE values to fit a model in the Model chapter.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "transform.html#combining-everything",
    "href": "transform.html#combining-everything",
    "title": "6  Transform",
    "section": "6.5 Combining Everything",
    "text": "6.5 Combining Everything\nNow that we have the metrics we will use in the Model chapter, we will combine them into a single data frame to make the modelling as straightforward as possible. We also make a plot of the average values by pick each metric, note that no points can be directly on top of each other because all points have different overall values. When we fit the models we will use the raw values, but as seen in the Visualize chapter it is basically impossible to infer anything from the raw value plots. Note that the following two Stack Overflow posts were particularly helpful when writing this code:\n\nDynamic Variable naming in r\nSpecifying column with its index rather than name\n\n\n\nCode\nall_data_comb &lt;- all_data_adj |&gt; \n  group_by(overall) |&gt; \n  summarize(mean_ps = mean(ps), \n            mean_gp = mean(gp), \n            mean_adj_ps = mean(adj_ps),\n            suc_rate = mean(reg))\n\nmetrics &lt;- c(\"mean_ps\", \"mean_gp\", \"mean_adj_ps\", \"suc_rate\")\nnames &lt;- c(\"Mean PS\", \"Mean GP\", \"Mean Adjusted PS\", \"Success Rate\")\n\nfor(i in 1:length(metrics)){\n  assign(str_glue(\"plot_{metrics[i]}\"), \n         ggplot(all_data_comb, aes_string(x = \"overall\", y = metrics[i])) + \n           geom_point() + \n           labs(title = str_glue(\"{names[i]} verses Overall\"), \n                x = \"Overall\", y = str_glue(\"{names[i]}\")))\n}\n\n(plot_mean_ps + plot_mean_gp) / (plot_mean_adj_ps + plot_suc_rate)\n\n\n\n\n\n\n\n\n\nThese plots all have the same general shape, though some of them are on different scale. In the next chapter we will fit a model to the raw data, put the models on the same scale, and evaluate the models.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "transform.html#storing-the-transformations",
    "href": "transform.html#storing-the-transformations",
    "title": "6  Transform",
    "section": "6.6 Storing the Transformations",
    "text": "6.6 Storing the Transformations\nAs touched on at the very end of the Tidy chapter, we will be storing our data frames in our S3 bucket. We use the same code to add all_data_adj and all_data_comb to our S3 bucket within AWS. In functions.R we get these data frames by querying the S3 bucket using duckdb.\n\n\nCode\nSys.setenv(\"AWS_ACCESS_KEY_ID\" = Sys.getenv(\"AWS_ACCESS_KEY_ID\"),\n           \"AWS_SECRET_ACCESS_KEY\" = Sys.getenv(\"AWS_SECRET_ACCESS_KEY\"), \n           \"AWS_DEFAULT_REGION\" = \"us-east-2\")\nbucket = \"trevor-stat468\"\n\ns3write_using(all_data_adj, FUN = write_parquet, \n              bucket = bucket, object = \"all_data_adj.parquet\")\ns3write_using(all_data_comb, FUN = write_parquet, \n              bucket = bucket, object = \"all_data_comb.parquet\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Transform</span>"
    ]
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "7  Model",
    "section": "",
    "text": "7.1 Setup\nWe install and load the necessary packages, along with functions and data from prior chapters.\nCode\n# renv::install(\"patchwork\")\n# renv::install(\"stringr\")\n# renv::install(\"reactable\")\n# renv::install(\"pins\")\n# renv::install(\"vetiver\")\n# renv::install(\"plumber\")\n# renv::install(\"aws.s3\")\n\nlibrary(patchwork)\nlibrary(stringr)\nlibrary(reactable)\nlibrary(pins)\nlibrary(vetiver)\nlibrary(plumber)\nlibrary(aws.s3)\n\nsource(\"functions.R\") # load functions defined in prior chapters",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#introductionrecap",
    "href": "model.html#introductionrecap",
    "title": "7  Model",
    "section": "7.2 Introduction/Recap",
    "text": "7.2 Introduction/Recap\nNow that we have metrics representing different ways of calculating the historical value of a draft pick, we can now develop models for predicting the value of future picks. First, we will fit a linear regression model to the data, an then we will develop a model via non-linear regression. We will then put the models on the same scale by multiplying each predicted value by a constant, allowing us to compare models more effectively. Note that the following two Stack Overflow posts were once again very helpful when writing the code in this chapter:\n\nDynamic Variable naming in r\nSpecifying column with its index rather than name\n\nRecall the four plots we ended the Transform chapter with this plot, based on the mean PS, mean GP, success rate, and mean adjusted PS for every selection between 1 and 224. For convenience we replot this data below:\n\n\nCode\n(plot_mean_ps + plot_mean_gp) / (plot_mean_adj_ps + plot_suc_rate)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#linear-regression",
    "href": "model.html#linear-regression",
    "title": "7  Model",
    "section": "7.3 Linear Regression",
    "text": "7.3 Linear Regression\nWe use lm to fit a linear model to each of the metrics. Note we use a logistic regression model for fitting the model which estimates the probability of a player becoming an NHL regular.\n\n\nCode\nmetrics &lt;- c(\"ps\", \"gp\", \"adj_ps\")\noverall &lt;- all_data_adj$overall\n\nlin_models &lt;- lapply(metrics, \\(x) lm(all_data_adj[[x]] ~ overall))\n\nlogist_model &lt;- glm(all_data_adj$reg ~ overall, family = \"binomial\")\n\n\nFor each linear model, we generate the fitted values. The fitted values are given in the table below:\n\n\nCode\nlm_pred_vals &lt;- lapply(seq(1,3), \n                      \\(x) predict(lin_models[[x]], \n                                   data.frame(overall = seq(1,224))))\n\nlogist_pred_vals &lt;- predict(logist_model, data.frame(overall = seq(1,224)))\n\n\nlm_pred_vals &lt;- data.frame(overall = seq(1, 224), \n                          ps = lm_pred_vals[[1]], \n                          gp = lm_pred_vals[[2]], \n                          adj_ps = lm_pred_vals[[3]], \n                          p_reg = 1 / \n                            (1 + exp(-logist_pred_vals)))\n\nreactable(round(lm_pred_vals, 4))\n\n\n\n\n\n\nNext we plot the fitted values. The fitted lines are plotted on top of the average values, we use the average values to make the plot easier to read (but the lines were fit using the raw values).\n\n\nCode\nnames &lt;- c(\"PS\", \"GP\", \"Adjusted PS\", \"Probability of Success\")\n\nfor(i in 1:length(metrics)){\n  assign(str_glue(\"plot_{metrics[i]}\"), \n         ggplot(all_data_comb, aes_string(x = \"overall\", y = str_glue(\"mean_{metrics[i]}\"))) + \n           geom_point(alpha = 0.5) + \n           labs(title = str_glue(\"{names[i]} verses Overall\"), \n                x = \"Overall\", y = str_glue(\"{names[i]}\")))\n}\n\nfor(i in 1:length(metrics)){\n  assign(str_glue(\"plot_lm_{metrics[i]}\"), \n         get(str_glue(\"plot_{metrics[i]}\")) + \n           geom_line(data = lm_pred_vals, aes_string(x = \"overall\", y = metrics[i]), \n                     col = \"red\", lwd = 1.5))\n}\n\nplot_lm_p_reg = ggplot(all_data_comb, aes(x = overall, y = suc_rate)) + \n  geom_point(position = \"jitter\", alpha = 0.5) + \n  geom_line(data = lm_pred_vals, aes(x = overall, y = p_reg), col = \"red\", lwd = 1.5)\n\n(plot_lm_ps + plot_lm_gp) / (plot_lm_adj_ps + plot_lm_p_reg)\n\n\n\n\n\n\n\n\n\nBased on the plots above, all four of these linear models are inadequate. Moreover, all of the models except for the one based on NHL regular probability fail our second requirement for a feasible model, which is that all picks have a strictly positive value. With this in mind, we move onto fitting a non-linear model.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#non-linear-regression",
    "href": "model.html#non-linear-regression",
    "title": "7  Model",
    "section": "7.4 Non-Linear Regression",
    "text": "7.4 Non-Linear Regression\nGiven that none of the four linear models were appropriate, we will reattempt to fit a model using non-linear regression (ie the nls function, which stands for non-linear least squares). The resource Non-linear Regression in R was very helpful when working on this section. In short, we will be fitting the model\n\\[ v_{i,m} = \\frac{\\phi_{1, m}}{1+ (\\frac{e^{\\phi_{2,m}}}{i})^{1/\\phi_{3,m}}} \\]\nWhere\n\n\\(i\\) is the pick number.\n\\(m\\) is the metric being used.\n\\(v_{i,m}\\) is the value of pick \\(i\\) based on metric \\(m\\).\n\\(\\phi_{1, m},\\phi_{2, m},\\phi_{3, m}\\) are parameters we are estimating which depend on which metric we are using.\n\nWe choose to use nls because it allows us to directly fit a model with non-linear parameters, we do not need to transform the explanatory or response variates so it makes interpretations significantly easier. We fit the models using the same metrics as before except for the model based on whether players become NHL regulars.\n\n\nCode\nmetrics &lt;- c(\"ps\", \"gp\", \"adj_ps\")\n\noverall &lt;- all_data_adj$overall\n\nfor(i in seq(1,3)){\n  assign(str_glue(\"nls_{metrics[i]}\"), \n         nls(all_data_adj[[i+4]] ~ SSlogis(log(overall), phi1, phi2, phi3)))\n}\n\nnls_pred_vals &lt;- lapply(seq(1,3), \n                        \\(i) predict(get(str_glue(\"nls_{metrics[i]}\")), \n                                   data.frame(overall = seq(1,224))))\nnls_pred_vals &lt;- data.frame(overall = seq(1, 224), \n                          ps = nls_pred_vals[[1]], \n                          gp = nls_pred_vals[[2]], \n                          adj_ps = nls_pred_vals[[3]])\nreactable(round(nls_pred_vals, 4))\n\n\n\n\n\n\nWe now plot the fitted line. We once again use plot the line on top of the historical averages to make the plot easier to read.\n\n\nCode\nfor(i in seq(1,3)){\n  assign(str_glue(\"plot_nls_{metrics[i]}\"), \n         ggplot(all_data_comb, \n                aes_string(x = \"overall\", y = str_glue(\"mean_{metrics[i]}\"))) + \n           geom_point() + \n           geom_line(data = nls_pred_vals, \n                     aes_string(x = \"overall\", y = str_glue(\"{metrics[i]}\")), \n                     col = \"red\", lwd = 1.5))\n}\n\nplot_nls_ps / plot_nls_gp / plot_nls_adj_ps\n\n\n\n\n\n\n\n\n\nNow that we have fit the models, we plot the residual vs overall values. Note that typically we’d plot the residual vs fitted values, but this plot is impossible to make any inferences from because so many of the fitted values are relatively small, meaning they all get clumped together.\n\n\nCode\nall_resids &lt;- data.frame(overall = all_data_adj$overall, \n                         ps_resid = all_data_adj$ps - predict(nls_ps, overall) , \n                         gp_resid =  all_data_adj$gp - predict(nls_gp, overall), \n                         adj_ps_resid = all_data_adj$adj_ps - predict(nls_adj_ps, overall))\n\nfor(i in seq(1,3)){\n  assign(str_glue(\"plot_resid_{metrics[i]}\"), \n         ggplot(all_resids, aes_string(x = \"overall\", y = str_glue(\"{metrics[i]}_resid\"))) + \n           geom_point(alpha = 0.3))\n}\n\nplot_resid_ps / plot_resid_gp / plot_resid_adj_ps\n\n\n\n\n\n\n\n\n\nThis clearly fails a number of the model assumptionts, most notably the assumption regarding a constant residual variance. This is not really that surprising and is not a major cause for concern as pretty much any feasible model will show the same general pattern for a few reasons. First, there is no upper bound on our residuals since (in theory) players can play in infinitely many games or generate infinite PS. However, there is a lower bound on the residuals because if a player never plays in an NHL game and/or never generates any PS, then the associated residual will be the predicted value. That is, there is a limit to how much a player can underperform relative to draft position (since we don’t allow negative PS and negative GP is not possible), but there is no limit to how much they can overperform. One other thing to note is that, generally speaking, there seems to be more variance among earlier picks than later picks because earlier picks can over or underperform a lot, while later picks can overperform a lot or underperform a little (because their expectations are lower, even if they do nothing they didn’t underperform that much).\nWe will look at a QQ Plot of the residuals. This ggplot2 documentation page was very helpful for this part.\n\n\nCode\nfor(i in seq(1,3)){\n  assign(str_glue(\"qq_{metrics[i]}\"), \n         ggplot(all_resids, aes_string(sample = str_glue(\"{metrics[i]}_resid\"))) + \n           stat_qq() + \n           stat_qq_line(col = \"red\", lwd = 0.5))\n}\n\nqq_ps / qq_gp / qq_adj_ps\n\n\n\n\n\n\n\n\n\nClearly the residuals are not normally distributed. This is another result of the points mentioned above, that there is a lower bound on a player’s underperformance, but no upper bound on how much they can overperform.\nThe lesson to take from these plots is that deriving confidence intervals or calculating p-values is almost certainly a bad idea because the assumptions that those mechanisms rely on are clearly invalid. On the other hand, taking point estimates is probably okay since we effectively found a line of best fit which doesn’t rely on any of the model assumptions. With this in mind, we will be relying on the point estimates given by this model for the remainder of this report.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#model-selection",
    "href": "model.html#model-selection",
    "title": "7  Model",
    "section": "7.5 Model Selection",
    "text": "7.5 Model Selection\nFor convenience we replot the fitted values from the non-linear models we fit in the last section.\n\n\nCode\nplot_nls_ps + plot_nls_gp + plot_nls_adj_ps\n\n\n\n\n\n\n\n\n\nOne problem with these plots is that they’re all on different scales, which makes comparing models very difficult. Recall from the Introduction chapter that we want to end up with a model which has \\(\\hat v_1 = 1000\\) “points” to maintain consistency with existing work. To do this, we set \\(C_m = \\frac{1000}{v_{1,m}}\\), and then multiply all of the other \\(\\hat v_{i,m}\\) values by \\(C_m\\) for \\(i \\not= 1\\), and then use reactable to make sure it worked.\n\n\nCode\nC_m &lt;- c(1, 1000 / nls_pred_vals[1,-1])\n\nscaled_vals &lt;- nls_pred_vals * C_m\n\nreactable(round(scaled_vals, 4))\n\n\n\n\n\n\nThis seems to look good. Now that the predicted values are on the same scale, we can plot them on top of each other.\n\n\nCode\nggplot(scaled_vals, aes(x = overall)) + \n  geom_line(aes(y = ps), col = \"blue\", lwd = 1.2) + \n  geom_line(aes(y = gp), col = \"limegreen\", lwd = 0.75) + \n  geom_line(aes(y = adj_ps), col = \"salmon\", lwd = 0.8, lty = 4)\n\n\n\n\n\n\n\n\n\nInterestingly, the PS and Adjusted PS lines are basically directly on top of each other, which implies that the adjustment we made had little impact on the predictions. We can also compare the residual sum of squares without rescaling all the values and refitting the models by simply multiplying the RSS values by the appropriate \\(C_m\\): Why doesn’t this work???\n\\[RSS_m  = \\sum^n_{i=1}(\\hat v_{i,m} - v_i)^2 \\Longrightarrow RSS \\times C_m^2 = \\sum^n_{i=1}(C_m\\hat v_{i,m} - C_mv_i)^2 \\]\n\n\nCode\nsummary(nls_ps)\n\n\n\nFormula: all_data_adj[[i + 4]] ~ SSlogis(log(overall), phi1, phi2, phi3)\n\nParameters:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nphi1 162.40720   20.72857   7.835  5.6e-15 ***\nphi2   0.44022    0.28595   1.540    0.124    \nphi3  -1.21381    0.05159 -23.527  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 18.05 on 5422 degrees of freedom\n\nNumber of iterations to convergence: 2 \nAchieved convergence tolerance: 1.614e-06\n\n\nCode\nsummary(nls_gp)\n\n\n\nFormula: all_data_adj[[i + 4]] ~ SSlogis(log(overall), phi1, phi2, phi3)\n\nParameters:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nphi1 983.47691   53.06846   18.53   &lt;2e-16 ***\nphi2   2.30269    0.13060   17.63   &lt;2e-16 ***\nphi3  -1.02498    0.04346  -23.59   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 233.1 on 5422 degrees of freedom\n\nNumber of iterations to convergence: 3 \nAchieved convergence tolerance: 7.857e-07\n\n\nCode\nsummary(nls_adj_ps)\n\n\n\nFormula: all_data_adj[[i + 4]] ~ SSlogis(log(overall), phi1, phi2, phi3)\n\nParameters:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nphi1 179.18880   19.86941   9.018   &lt;2e-16 ***\nphi2   0.56971    0.24867   2.291    0.022 *  \nphi3  -1.18730    0.04728 -25.111   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.83 on 5422 degrees of freedom\n\nNumber of iterations to convergence: 2 \nAchieved convergence tolerance: 6.537e-07\n\n\nCode\nC_m\n\n\n[[1]]\n[1] 1\n\n$ps\n[1] 10.44172\n\n$gp\n[1] 1.124339\n\n$adj_ps\n[1] 9.034525\n\n\nSo the scaled sum of squares are:\n\n\nCode\nRSS &lt;- c(18.05, 233.1, 19.83)\nRSS * unlist(C_m[-1])\n\n\n      ps       gp   adj_ps \n188.4730 262.0834 179.1546 \n\n\nRecall that since the correlation between PS and GP was \\(\\approx\\) 0.85, we will not use a model which incorporates both due to multicollinearity concerns. Given the choice, we prefer to use a metric based on PS rather than GP for a few reasons.\n\nPS credits players for contributing to their team, whereas GP gives credit for being good enough to play for a team.\nThe RSS associated with the model with GP is significantly higher than the RSS for both of the PS-related models.\nWhile both metrics are right skewed, in this context we prefer a metric which has a longer right tail since this will allow us to distinguish good players from elite players. Specifically, there is a hard cap on how many games a player can play in a certain time frame, but the limit on PS is impossible to reach (a player would have to win every game in his career and be fully responsible for each and every win). In other words, if two players each played in 82 games per season for 10 seasons before retiring, they would both have played in 820 games, but their PS values could be quite different, indicating that PS is a more distinguishing metric. We know PS has a longer tail because the maximum of PS is more standard deviations away from the mean than the maximum of GP, as we showed at the start of our EDA in the Visualize chapter.\nThe PS formula includes time on ice, which tends to be a better measure of player involvement than GP. For example, Player A who plays 20 minutes a night and and Player B who plays 10 minutes a night may have the same GP, but Player A would likely be considered more valuable because he plays twice as much.\n\nNow that we’ve settled either using PS or Adjusted PS, we take a closer look at the difference between their predicted values. The mean disparity between the two predicted values is about 1.04, which indicates the metric we choose is unlikely to significantly impact our conclusion since picks are values out of 1000. Note that we need to take the absoute value since the since the scaled version of Adjusted PS may be smaller than the scaled PS values.\n\n\nCode\nmean(abs(scaled_vals$adj_ps - scaled_vals$ps))\n\n\n[1] 1.044389\n\n\nWe can also plot the percent differences.\n\n\nCode\nggplot(scaled_vals, aes(x = overall)) + \n  geom_line(aes(y = ps / adj_ps), col = \"dodgerblue\") + \n  geom_line(aes(y = adj_ps / ps), col = \"salmon\")\n\n\n\n\n\n\n\n\n\nWe see that most of the variation between the PS and Adjusted PS values occurs late in the draft, but these picks are very close in raw point values since 3% of a relatively small number is a small number. With this in mind, we choose the model based on PS (not Adjusted PS). As the analysis in this section has showed, there is almost zero difference between the models based on PS and Adjusted PS models. Therefore we prefer to use the simpler model, which in this case is PS. The RSS values for both models are fairly close, and even though the RSS is smaller for Adjusted PS we will chose the PS model due to it being a simpler model.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#finishing-touches",
    "href": "model.html#finishing-touches",
    "title": "7  Model",
    "section": "7.6 Finishing Touches",
    "text": "7.6 Finishing Touches\nTo make the rest of this report and shiny app simpler, we will refit the model with scaled PS values:\n\n\nCode\nscal_ps &lt;- all_data_adj$ps * C_m[[2]]\n\nnls_scal_ps &lt;- nls(scal_ps ~ SSlogis(log(overall), phi1, phi2, phi3))\n\nsummary(nls_scal_ps)\n\n\n\nFormula: scal_ps ~ SSlogis(log(overall), phi1, phi2, phi3)\n\nParameters:\n       Estimate Std. Error t value Pr(&gt;|t|)    \nphi1 1695.81037  216.44187   7.835  5.6e-15 ***\nphi2    0.44022    0.28595   1.540    0.124    \nphi3   -1.21381    0.05159 -23.527  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 188.5 on 5422 degrees of freedom\n\nNumber of iterations to convergence: 2 \nAchieved convergence tolerance: 1.614e-06\n\n\nWe now create two functions which will be used in our R Shiny app. The first is value, which takes in a pick and returns the number of points (a more user-friendly version of predict), and the second is pick, which takes in a number of point and returns the closest pick to that number of points. Recall we fit the model \\[ v_{i,m} = \\frac{\\phi_{1, m}}{1+ (\\frac{e^{\\phi_{2,m}}}{i})^{1/\\phi_{3,m}}} \\]and we found \\(\\phi_{1,m} = 1695.81038, \\phi_{2,m} = 0.4402, \\phi_{3,m} = -1.21381\\). Creating the value function is now straightforward.\n\n\nCode\nphis &lt;- unname(coef(nls_scal_ps))\nphi_1 &lt;- phis[1]\nphi_2 &lt;- phis[2]\nphi_3 &lt;- phis[3]\n\nvalue &lt;- function(overall){\n  phi_1 / (1 + (exp(phi_2) / overall)^(1 / phi_3))\n}\n\n# check it worked:\nvalue(1) # should be 1000 \n\n\n[1] 1000\n\n\nCode\nvalue(224) # should be approx 27.762\n\n\n[1] 27.7623\n\n\nThe pick function is more complex, we need to take the inverse of the value function. It’s not a difficult computation and it’s a few steps so we omit the steps, it turns out the inverse is given below:\n\\[\ni = \\frac{e^{\\phi_{2,m}}}{(\\frac{\\phi_{1,m}}{v_{i,m}} - 1)^{\\phi_{3,m}}}\n\\]\n\n\nCode\npick &lt;- function(value){\n  round(exp(phi_2) / ((phi_1 / value - 1)^phi_3))\n}\n\n# check it worked:\npick(1000) # should be 1 \n\n\n[1] 1\n\n\nCode\npick(27.76) # should be 224\n\n\n[1] 224\n\n\nCode\ni &lt;- seq(1, 224)\nall(pick(value(i)) == i)\n\n\n[1] TRUE\n\n\nNote that the value and pick functions we implemented in R are not perfect inverses of each other because of the use of round, but for the purposes of our R Shiny app this will not be an issue. As one final check, we see what the difference in values was for a recent NHL trade in which the Philadelpha Flyers acquired the 12th overall selection from the Pittsburgh Penguins in exchange for the 22nd and 31st selections. We can see that this difference is about 39 points, which is equivalent to Pittsburgh receiving a mid 5th round pick in surplus value. This seems about right, it is widely accepted that the team that acquires the highest pick almost always gives up more than they receive. This is why teams only trade up if they really like a player who is available at the current pick, but that the team thinks will not be available at their next pick.\n\n\nCode\nvalue(12) - value(22) - value(31)\n\n\n[1] -38.92649\n\n\nCode\npick(abs(value(12) - value(22) - value(31)))\n\n\n[1] 147\n\n\nFinally, we create a data frame of predicted values and store it in our S3 bucket:\n\n\nCode\nSys.setenv(\"AWS_ACCESS_KEY_ID\" = Sys.getenv(\"AWS_ACCESS_KEY_ID\"),\n           \"AWS_SECRET_ACCESS_KEY\" = Sys.getenv(\"AWS_SECRET_ACCESS_KEY\"), \n           \"AWS_DEFAULT_REGION\" = \"us-east-2\")\nbucket = \"trevor-stat468\"\n\npred_vals &lt;- data.frame(overall = seq(1,224), \n                        pts = cbind(lapply(seq(1,224), value)))\n\ns3write_using(data.frame(overall = all_data_adj$overall, ps = scal_ps), \n              FUN = write_parquet, bucket = bucket, object = \"scal_ps.parquet\")\ns3write_using(pred_vals, FUN = write_parquet, \n              bucket = bucket, object = \"pred_vals_nls.parquet\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "model.html#storing-a-model",
    "href": "model.html#storing-a-model",
    "title": "7  Model",
    "section": "7.7 Storing a Model",
    "text": "7.7 Storing a Model\nWe now store the model and data in an S3 bucket so we can access them from within our Shiny app. Note that some of the steps given on DevOps for Data Science were in Python, I found the equivalent R steps here. Since vetiver cannot be used for nls objects, we will use it on the logistic model using success rate to show that I know how to do it. There will be 2 versions of the app, one using the logistic model (which satisfies the devops requirements) and one using the nls model (which has objectively better predictions, as explained earlier in this chapter).\n\n\nCode\nlogist_model &lt;- glm(all_data_adj$reg ~ overall, family = \"binomial\")\n\ns3write_using(data.frame(overall = seq(1,224), \n                         pts = predict(logist_model, \n                                       data.frame(overall = seq(1,224)))), \n              FUN = write_parquet, \n              bucket = bucket, object = \"pred_vals_logist.parquet\")\n\nv &lt;- vetiver_model(logist_model, \"logist_model\")\n\nboard &lt;- board_s3(bucket = bucket) \nvetiver_pin_write(board, v)\n\n\nCreating new version '20250811T161049Z-69ecb'\nWriting to pin 'logist_model'\n\nCreate a Model Card for your published model\n• Model Cards provide a framework for transparent, responsible reporting\n• Use the vetiver `.Rmd` template as a place to start\n\n\nWe now proceed to the Communication chapter, which contains the key results from this report.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Model</span>"
    ]
  },
  {
    "objectID": "communicate.html",
    "href": "communicate.html",
    "title": "8  Communicate",
    "section": "",
    "text": "8.1 Setup\nWe install and load the necessary packages, along with functions from prior chapters.\nCode\n# renv::install(patchwork)\n# renv::install(reactable)\n\nlibrary(patchwork)\nlibrary(reactable)\n\nsource(\"functions.R\") # load functions defined in prior chapters",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Communicate</span>"
    ]
  },
  {
    "objectID": "communicate.html#shiny-apps",
    "href": "communicate.html#shiny-apps",
    "title": "8  Communicate",
    "section": "8.2 Shiny Apps",
    "text": "8.2 Shiny Apps\nAs mentioned in the Model chapter, there are two shiny apps associated with this project. The first, linked here, uses non-linear regression to make predictions based on the PS of future picks. If I was advising a team, this is the model I would suggest using. The second app, linked here, uses logistic regression to make predictions based on the expected value of each pick, which is the probability of the player selected at that pick becoming an NHL regular. Disclaimer: adding probabilities in this manner is dubious at best from a statistical perspective, but vetiver does not easily support nls objects as mentioned in the Model chapter, so I needed to use a model from lm or glm, in order to satisfy many of the the devops requirements for this app. Using expected NHLers as the interpretation of pick value allows us to add values together, but the predictions are just not that good (it values pick 1 as pick 50 + pick 100, if any NHL GM traded the first overall pick for these two picks they would be fired on the spot).\nThe apps differ only in the models they are based on (and their underlying code to access predictions, the logistic-based app has logging, and the nls-based app does not for example). Their UIs are almost identical (except for some asthetic differences), so the instructions for both apps are exactly the same, though the included screenshots are only for the app based on the model fit via non-linear regression.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Communicate</span>"
    ]
  },
  {
    "objectID": "communicate.html#usage-of-the-app",
    "href": "communicate.html#usage-of-the-app",
    "title": "8  Communicate",
    "section": "8.3 Usage of the App",
    "text": "8.3 Usage of the App\nUsage of the app is very straightforward. Users can enter the picks into boxes under the appropriate team. The app responds by adding the picks to the below tables as the user types, allowing the user to visually estimate the trade before evaluating. A screenshot of part of the UI before “Evaluate Trade” is clicked is shown in Figure 8.3.1:\n\n\n\nFigure 8.3.1: Entering Picks in the App\n\n\nThere is also a plot at the bottom of all picks in the draft so users can roughly estimate the value of all picks without needing a massive table. This plot also colours points as the user types, as shown in Figure 8.3.2:\n\n\n\nFigure 8.3.2: Graph of Pick Values\n\n\nWhen the user clicks “Evaluate Trade!” there are three messages that come up. The first two tell the user how many points each team is trading away. Though sort of trivial in this example (since Team A only trades one pick) this can be quite useful in trades where more than a few picks are being exchanged. The last message is a summary which says who loses the trade, how many points they lose it by, and what pick this is equivalent to. The equivalent pick is (usually, more on this shortly) the pick which is closest to the point difference is important because it gives the user context on how big the difference is, which is difficult to do using points since they are unitless. This is shown in Figure 8.3.3 below:\n\n\n\nFigure 8.3.3: Evaluating a Trade\n\n\nThere are a number of possible messages that can come up depending on the trade’s point difference, to give the user more context on the trade. Some of the possible messages are given in Figures 8.3.4 and 8.3.5 below:\n\n\n\nFigure 8.3.3: Evaluating a Trade\n\n\n\n\n\nFigure 8.3.3: Evaluating a Trade\n\n\nThe app also has a message for if the difference is &lt; 0.001 points, but it turns out to be quite difficult to find a trade which is this close. The app also protects the user from doing things that don’t make sense. For example, clearly the only values that should be used are positive integers (for example pick -1 and pick 17.4 don’t make sense). Additionally, the last pick in the draft is pick 224, so any positive integer greater than 224 should be banned too. If there are invalid inputs, the user will be visually warned, and the app will refuse to evaluate the value of picks for the affected team(s) and any comparisons. In the app based on the logistic model, this is considered an ERROR for logging purposes. Furthermore, the tables and plots will also not render until all picks are valid. Note the app will still calculate the total points for one team if all of their picks are valid. We see examples of this in Figures 8.3.6 and 8.3.7:\n\n\n\nFigure 8.3.6: Both Teams have Invalid Picks (Nothing Renders)\n\n\n\n\n\nFigure 8.3.7: One Team has Invalid Picks (Team B Still Renders)\n\n\nAnother possible situation is if picks are duplicated (either one team trades the same pick twice or both teams give up the pick). In this case, there is nothing technically wrong with the trade, so the user will be visually warned but the text, tables, and plots will render. In the logistic model, this is considered a WARN for logging purposes. An example of this is given in Figure 8.3.8:\n\n\n\nFigure 8.3.8: Duplicated Picks\n\n\nif there are duplicated picks which are also invalid, the user will be warned for both and nothing will render for either team. This is logged as an ERROR in the logistic model. This is shown in Figure 8.3.9:\n\n\n\nFigure 8.3.9: Duplicated Invalid Picks\n\n\n3 team trades are incredibly rare in the NHL so they are not directly included in the app, though they could be analyzed by looking at what each team individually receives and gives up (ie look at it in terms of 3 two team trades).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Communicate</span>"
    ]
  },
  {
    "objectID": "communicate.html#summary-of-results",
    "href": "communicate.html#summary-of-results",
    "title": "8  Communicate",
    "section": "8.4 Summary of Results",
    "text": "8.4 Summary of Results\nWe also present two other summaries of the results. First, we have a plot of the value of each pick, note that a geom_point() version of these exact plots are used in the shiny apps\n\n\nCode\nggplot(pred_vals_nls, aes(x = overall, y = as.numeric(pts))) + \n  geom_line() + \nggplot(pred_vals_logist, aes(x = overall, y = 1/(1+exp(-as.numeric(pts))))) + \n  geom_line()\n\n\n\n\n\n\n\n\n\nWe also provide a table of all predicted pick values based on the models.\n\n\nCode\nreactable(data.frame(cbind(pred_vals_nls, \n                           1/(1+exp(-pred_vals_logist[2])))))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Communicate</span>"
    ]
  },
  {
    "objectID": "communicate.html#things-to-do",
    "href": "communicate.html#things-to-do",
    "title": "8  Communicate",
    "section": "8.5 Things to do:",
    "text": "8.5 Things to do:\n\nGithub Actions\nAdd references to .bib file\nRead thru instructions to see if I’m missing anything\nGive all plots titles and labels\nRemove unnecessary library calls\nMake sure everything flows logically, make notation consistent\nmake sure links work, make sure links are in bibliography\nAdd comments to code\nSpell check\nremove unnecessary files from github (ie holding_file, model2, etc).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Communicate</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "AI\nThe following is a list of all sources used to complete this report. The resources are organized by the type of source, note that a more formal bibliography is given in my references.bib file.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#ai",
    "href": "references.html#ai",
    "title": "References",
    "section": "",
    "text": "ChatGPT Usage (will add link when done)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#articlesblog-posts",
    "href": "references.html#articlesblog-posts",
    "title": "References",
    "section": "Articles/Blog Posts",
    "text": "Articles/Blog Posts\n\nCalculating Point Shares (throughout the report)\nExamining the value of NHL Draft picks (for background info on previous work)\nHow to read and write data from and to S3 bucket using R? (for putting data into an S3 bucket)\nHow to work with remote Parquet files with the duckdb R package? (for more help putting data into an S3 bucket)\nNHL draft: What does it cost to trade up? (for background info on previous work)\nNon-linear Regression in R (to create the non-linear regression models)\nThe Ultimate Guide to Deploying a Shiny App on AWS (massively helpful with the Dev Ops-related components of the Shiny app)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#books",
    "href": "references.html#books",
    "title": "References",
    "section": "Books",
    "text": "Books\n\nDevOps for Data Science (throughout the report)\nHappy Git and GitHub for the useR (throughout the report)\nMastering Shiny (for the Shiny app)\nR for Data Science (2e) (throughout the report)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#papers",
    "href": "references.html#papers",
    "title": "References",
    "section": "Papers",
    "text": "Papers\n\nDETERMINING THE VALUE OF NBA DRAFT PICKS USING ADVANCED STATISTICS (for background info on previous work in other sports)\n\n\n\nImproving NHL Draft Outcome Predictions using Scouting Reports (for the criteria used in the logistic model)\nMLB Rule IV Draft: Valuing Draft Pick Slots (for background info on previous work in other sports)\nValuation of NHL Draft Picks using Functional Data Analysis (for background info on previous work; my report also took a very similar approach to the one taken in this paper)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#miscellaneous",
    "href": "references.html#miscellaneous",
    "title": "References",
    "section": "Miscellaneous",
    "text": "Miscellaneous\n\nCreate a gt display table output element for Shiny (for the Shiny app)\nHockey Reference (for the data used in the report)\nNHL Draft Eligibility (for the rules of the NHL Entry Draft, was used in the Import chapter)\nThe R Installation Manager (for installing R in the EC2 instance)",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "references.html#stack-overflowforum-posts",
    "href": "references.html#stack-overflowforum-posts",
    "title": "References",
    "section": "Stack Overflow/Forum Posts",
    "text": "Stack Overflow/Forum Posts\n\nDynamic Variable naming in r (used to create variables within for loops, starting in the Transform chapter)\nRead/Write parquet file from s3 using R (to store the data in S3)\nShow different feedback warnings depending on single user input R Shiny (for the Shiny app)\nSpecifying column with its index rather than name (used to access specific columns within for loops, starting in the Transform chapter)",
    "crumbs": [
      "References"
    ]
  }
]